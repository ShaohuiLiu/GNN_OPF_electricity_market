{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ZHr-PzGkaBlE"},"outputs":[],"source":["# training on P100: 849MB memory, training loss decrease slow\n","# training on V100: 1255MB memory, training loss decrease much faster\n","\n","# ref bus is 639(640)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JKLovDeXoCCP"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import time\n","import math\n","from google.colab import drive\n","drive.mount('/content/drive')\n","device='cuda' if torch.cuda.is_available() else 'cpu'\n","print(torch.cuda.get_device_name(0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hj9_eLfoWQY3"},"outputs":[],"source":["filename='./drive/MyDrive/gnn/data/data_1354ac_2022/ieee1354_ISF.txt'\n","S_isf=pd.read_table(filename,sep=',',header=None).to_numpy() # ISF matrix\n","filename='./drive/MyDrive/gnn/data/data_1354ac_2022/ieee1354_fmax.txt'\n","f_max=pd.read_table(filename,sep=',',header=None).to_numpy() # flow limit\n","n_line = np.size(S_isf,0)\n","S = torch.from_numpy(S_isf).to(device) # ISF\n","f_max = torch.from_numpy(f_max).to(device) # flow limit\n","print(S.shape,f_max.shape,torch.min(f_max))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QF8DToBhDwqS"},"outputs":[],"source":["# x=np.load('/content/drive/MyDrive/gnn/data/dc118_p10_x.npy')\n","# y=np.load('/content/drive/MyDrive/gnn/data/dc118_p10_y.npy')\n","# All cases\n","# x=np.load('/content/drive/MyDrive/gnn/data/ac118_p10_x.npy')\n","# y=np.load('/content/drive/MyDrive/gnn/data/ac118_p10_y.npy')\n","# Normal cases\n","x=np.load('./drive/MyDrive/gnn/data/data_1354ac_2022/ac1354_x.npy')\n","y=np.load('./drive/MyDrive/gnn/data/data_1354ac_2022/ac1354_y.npy')\n","# x=np.load('/content/drive/MyDrive/gnn/data/data_118_quad/dc118_p10_x_normal1.npy')\n","# y=np.load('/content/drive/MyDrive/gnn/data/data_118_quad/dc118_p10_y_normal1.npy')\n","W=np.load('./drive/MyDrive/gnn/data/data_1354ac_2022/ac1354_w.npy')\n","# W=np.load('/content/drive/MyDrive/gnn/data/ac118_p10_w.npy')\n","print(x.shape,y.shape)\n","print(np.max(x),np.min(x),np.max(y),np.min(y))\n","\n","# scaling on voltage\n","y[:,1,:] = (y[:,1,:] - 0.8) * 100\n","print('voltage:',np.min(y[:,1,:]),np.max(y[:,1,:]))\n","\n","from sklearn.model_selection import train_test_split\n","x_train,x_test,y_train,y_test = train_test_split(x.transpose(),y.transpose(),test_size=0.2, random_state=18)\n","x_train=x_train.transpose()\n","x_test=x_test.transpose()\n","y_train=y_train.transpose()\n","y_test=y_test.transpose()\n","print('Training data size:',x_train.shape)\n","print('Training label size:',y_train.shape)\n","\n","class Dataset(torch.utils.data.Dataset):\n","    def __init__(self, features, labels, device='cpu'):\n","        self.features=torch.from_numpy(np.transpose(features)).float().to(device)\n","        self.labels=torch.from_numpy(np.transpose(labels)).float().to(device)\n","    def __len__(self):\n","        return len(self.features)\n","    def __getitem__(self, idx):\n","        if torch.is_tensor(idx): idx = idx.tolist()\n","        # Select sample\n","        X = self.features[idx]  # shape = (24,)\n","        y = self.labels[idx]    # shape = (24,)\n","        X = torch.reshape(X,(6,1354))\n","        y = torch.reshape(y,(2,1354))\n","        return X, y\n","params = {'batch_size': 256,\n","          'shuffle': True,\n","          'num_workers': 0}\n","# Dataset Generators\n","training_set = Dataset(features=x_train,labels=y_train,device=device)\n","training_generator = torch.utils.data.DataLoader(training_set,**params)\n","validation_set = Dataset(features=x_test,labels=y_test,device=device)\n","validation_generator = torch.utils.data.DataLoader(validation_set,**params)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Us8lAo_P6NDy"},"outputs":[],"source":["# voltage range\n","print('voltage:',np.min(y[:,1,:]),np.max(y[:,1,:]))\n","print('price:',np.min(y[:,0,:]),np.max(y[:,0,:]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JN9gN9BnCNim"},"outputs":[],"source":["fig2 = plt.figure(figsize=(16, 8))\n","flat_list = list(np.concatenate(y[:,1,:]).flat)\n","flat_list3 = list(np.concatenate(y[:,0,:]).flat)\n","plt.subplot(1,2,1)\n","plt.hist(flat_list,bins = 100)\n","plt.subplot(1,2,2)\n","plt.hist(flat_list3,bins = 100)\n","# plt.plot(err_L2,'bo',markersize=0.5,label = 'L2 error')"]},{"cell_type":"markdown","metadata":{"id":"WjzEy-twfPvI"},"source":["* Normalize the power of Laplacian"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jp3zMPW7NUb_"},"outputs":[],"source":["W1 = W.copy()\n","W1 = np.asarray(W1)\n","# print(np.asarray([[2,3],[4,7]])/5)\n","W1 = W1 / 1\n","W2 = W1.copy()\n","print(type(W))\n","lam,v = np.linalg.eig(W1)\n","print(lam[0])\n","for i in range(5):\n","  W1 = np.matmul(W1,W2) / np.max(np.matmul(W1,W2))\n","  # print(W1)\n","  lam,v = np.linalg.eig(W1)\n","  print(lam[0])#/10**(i+1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ncIvnFYszV5H"},"outputs":[],"source":["def numparam(in_feats,out_feats): return 4*476+in_feats*out_feats+out_feats\n","indexes=[1,10,15,15,10,10,1]\n","total=0\n","for temp in range(len(indexes)-1):\n","  total+=numparam(indexes[temp],indexes[temp+1])\n","print(total)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J2fkZxWsoCGP"},"outputs":[],"source":["from torch.autograd import Variable\n","# One layer Graph convolution from nodes to edges\n","class Graph_convolution_v2v_W(nn.Module):\n","    def __init__(self,in_features,out_features,W,n,bias=True):\n","        super(Graph_convolution_v2v_W,self).__init__()\n","        self.register_buffer('w',torch.from_numpy(W.transpose()).float())\n","        self.register_buffer('n0',torch.tensor(n))\n","        self.mapping=nn.Parameter(torch.Tensor(n,W.shape[0],W.shape[1]))\n","        torch.nn.init.xavier_uniform_(self.mapping.data)\n","        self.scale0=nn.Parameter(torch.Tensor(out_features,in_features))\n","        torch.nn.init.xavier_uniform_(self.scale0.data)\n","        self.scale=nn.Parameter(torch.Tensor(n-1,out_features,out_features))\n","        torch.nn.init.xavier_uniform_(self.scale.data)\n","        self.bias=nn.Parameter(torch.Tensor(out_features,1))\n","        torch.nn.init.xavier_uniform_(self.bias.data)\n","\n","    def forward(self,input):\n","        h=torch.mul(self.mapping[0,:,:],self.w) # element-wise\n","        h=torch.matmul(input,h) # transpose due to batch generator\n","        h=torch.matmul(self.scale0,h)\n","        for i in range(self.n0 - 1):\n","          W1 = torch.matrix_power(self.w,i+2)/torch.max(torch.matrix_power(self.w,i+2))\n","          h1=torch.mul(self.mapping[i,:,:],W1)\n","          h=torch.matmul(h,h1) # transpose due to batch generator \n","          h=torch.matmul(self.scale[i,:,:],h)\n","        return h+self.bias \n","\n","# GNN using DGL v2v graph convolution and our own v2e graph convolution\n","class GCN(nn.Module):\n","    def __init__(self, in_feats, hidden_size, W, num_bus, n_hop):\n","        super(GCN, self).__init__()\n","        self.conv_v2v1=Graph_convolution_v2v_W(in_feats,hidden_size[0],W,n_hop)\n","        self.conv_v2v2=Graph_convolution_v2v_W(hidden_size[0],hidden_size[1],W,n_hop)\n","        self.conv_v2v3=Graph_convolution_v2v_W(hidden_size[1],hidden_size[2],W,n_hop)\n","        self.conv_v2v4=Graph_convolution_v2v_W(hidden_size[2],hidden_size[3],W,n_hop)\n","        self.conv_v2v5=Graph_convolution_v2v_W(hidden_size[3],hidden_size[4],W,n_hop)\n","        self.conv_v2v6=Graph_convolution_v2v_W(hidden_size[4],hidden_size[5],W,n_hop)\n","        # self.conv_v2v7=Graph_convolution_v2v_W(hidden_size[5],hidden_size[6],W,n_hop)\n","        # self.conv_v2v8=Graph_convolution_v2v_W(hidden_size[6],hidden_size[7],W,n_hop)\n","        self.lin_output = nn.Linear(num_bus,num_bus)\n","         \n","    def forward(self, inputs):\n","        # m = nn.ELU()\n","        # m = nn.LeakyReLU()\n","        # m = nn.Tanh()\n","        m = nn.ReLU()\n","        h=self.conv_v2v1(inputs)\n","        h=m(h)\n","        h=self.conv_v2v2(h)\n","        h=m(h)\n","        h=self.conv_v2v3(h)\n","        h=m(h)\n","        h=self.conv_v2v4(h)\n","        h=m(h)\n","        h=self.conv_v2v5(h)\n","        h=m(h)\n","        h=self.conv_v2v6(h)\n","        h=torch.relu(h)\n","        h = self.lin_output(h)\n","        # time.sleep(5)\n","        return h\n","n_bus=x.shape[0]\n","# w_params=[10,15,10,1]\n","w_params=[5,10,10,5,5,2]\n","n_hop = 2\n","# W = W / 10 # normalize\n","net=GCN(6,w_params,W,n_bus, n_hop) # Laplacian\n","net=net.to(device)\n","\n","# set loss_func & optimizer\n","\n","optimizer=torch.optim.Adam(net.parameters())\n","loss_optm=[]\n","loss_val=[]\n","print(net)\n","print('number of params: %d'%(sum(temp.numel() for temp in net.parameters() if temp.requires_grad)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LhbrlrZHXrYv"},"outputs":[],"source":["# Number of parameters in net\n","n_params = 0\n","n_params_trainable = 0\n","for temp in net.parameters():\n","    # print(temp.shape[0])\n","    # print(temp.shape)\n","    n_params += temp.numel()\n","    if abs(temp.shape[0] - n_bus) > 0:\n","      n_params_trainable += temp.shape[0] * temp.shape[1]\n","    else:\n","      n_params_trainable += n_bus + 2 * n_line\n","print('Number of GNN parameters:',n_params)\n","print('Number of effective GNN parameters:',n_params_trainable)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GEQ-MDKOTqW1"},"outputs":[],"source":["# threshold function for p_g\n","class my_gen_pred_binary(nn.Module):\n","  def __init__(self):\n","    super(my_gen_pred_binary,self).__init__()\n","  def forward(self,x,thresh):\n","    # thresh=torch.tensor(thresh).double()\n","    # print(thresh,thresh.dtype)\n","    # print(x.dtype,x)\n","    right_thresh=torch.tensor(thresh).double()\n","    left_thresh=torch.tensor(0).double()\n","    x=x.double()\n","\n","\n","    # output=torch.where(x<left_thresh,0.,x)\n","    # output=torch.where(output>right_thresh,right_thresh,output)\n","\n","    # 1st layer\n","    output = torch.sigmoid(left_thresh - x)\n","    output = torch.mul(output,left_thresh - x) + x\n","    # 2nd layer\n","    output = torch.sigmoid(output - right_thresh)\n","    output = torch.mul(output,output - right_thresh) + right_thresh\n","\n","    # output=torch.where(output*output<thresh*thresh,output/thresh,output)\n","    return output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9mYCMszHaosA"},"outputs":[],"source":["## params needed for S calculation\n","# line parameters\n","filename1 = './drive/MyDrive/gnn/data/data_1354ac_2022/ieee1354_lineloc.txt'\n","# filename2 = 'data_1354ac_2022/ieee1354_lineparams.txt'\n","filename2 = './drive/MyDrive/gnn/data/data_1354ac_2022/ieee1354_lineparams_tap.txt'\n","filename3 = './drive/MyDrive/gnn/data/data_1354ac_2022/ieee1354_Bbus.txt'\n","# incidence info\n","line_loc = pd.read_table(filename1,sep=',',header=None).to_numpy()\n","# r, x, shunt, S_max\n","line_params = pd.read_table(filename2,sep=',',header=None).to_numpy()\n","B_mat=pd.read_table(filename3,sep=',',header=None).to_numpy()\n","\n","# remove transformers\n","n_line = 1751 # the rest are trabsformers\n","line_loc = line_loc[:n_line,:].copy()\n","line_params = line_params[:n_line,:].copy()\n","\n","B_r = np.delete(B_mat,639,axis=0) # ref bus\n","B_r = np.delete(B_r,639,axis=1)\n","Br_inv = np.linalg.inv(B_r)\n","\n","R_line = line_params[:,0].copy()\n","X_line = line_params[:,1].copy()\n","\n","B_shunt = line_params[:,2].copy()\n","\n","Z_line = R_line + 1j * X_line \n","Y_line = 1 / Z_line\n","\n","G_line = np.real(Y_line)\n","B_line = np.imag(Y_line)\n","\n","# transformer indicator\n","# a = (R_line > 0).astype(int)\n","a = np.ones(n_line)\n","\n","# s_max(f_max)\n","f_max = f_max[:n_line,:]\n","print(f_max.shape)\n","\n","# params to tensor and GPU\n","G_line_tensor = torch.from_numpy(G_line).to(device) # conductance\n","B_line_tensor = torch.from_numpy(B_line).to(device) # susceptance\n","B_shunt_tensor = torch.from_numpy(B_shunt/2).to(device) # conductance\n","Br_inv_tensor = torch.from_numpy(Br_inv).to(device) # reduced Bbus matrix\n","a_tensor = torch.from_numpy(a).double().to(device) # line/transformer\n","# n_batch = 256\n","# f_p = torch.zeros(n_line,n_batch).to(device)\n","# f_q = torch.zeros(n_line,n_batch).to(device)\n","# s_pred = torch.zeros(n_line,n_batch).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FUVO3etZn7bY"},"outputs":[],"source":["print(line_loc.shape,line_params.shape)\n","print(np.max(line_params[:,4]),line_params[1750,4])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Go4bwoEmoi0D"},"outputs":[],"source":["## define S-feasibility regularizer \n","gen_pred_binary_cell = my_gen_pred_binary() # threshold function\n","# S_ji regularizer\n","def sji_feas_reg(train_batch,pred_label,v_pred,binary_thres,s_max,G_line,B_line,B_shunt,Br_inv,a):#, \\f_p,f_q,s_pred):\n","  label1 = torch.squeeze(pred_label,1).transpose(0,1) # LMP: 118*batch \n","  p_max=train_batch[:,0,:].transpose(0,1) - train_batch[:,1,:].transpose(0,1)\n","  quadratic_b=train_batch[:,4,:].transpose(0,1)\n","  quadratic_a=train_batch[:,5,:].transpose(0,1)\n","  quadratic_center=(label1-quadratic_b)/(quadratic_a+1e-10)/2\n","  gen_pred_binary = gen_pred_binary_cell(quadratic_center,p_max)\n","  p_inj=gen_pred_binary\n","  bus_inj = p_inj + train_batch[:,1,:].transpose(0,1)\n","  p_inj_r = torch.cat((bus_inj[:639,:],bus_inj[640:,:])) / 100 # remove ref bus and to p.u., bus 69\n","  \n","## replace f by s_ij model\n","  theta0 = torch.matmul(Br_inv,p_inj_r) # approx bus angle w/ DC model\n","  ref_ang=torch.zeros(1,theta0.shape[1]).to(device)\n","  theta = torch.cat([theta0[:639,:],ref_ang,theta0[639:,:]],0) # insert, like np.insert\n","  v_pred = v_pred.transpose(0,1) / 100 + 0.8 # rescale to p.u.\n","  theta1 = theta[line_loc[:,1]-1,:]\n","  theta2 = theta[line_loc[:,0]-1,:]\n","  V1 = (v_pred[line_loc[:,1]-1,:]).double()\n","  V2 = (v_pred[line_loc[:,0]-1,:]).double() \n","\n","  f_p = torch.mul(torch.matmul(a,G_line),torch.mul(V1,V1)) \\\n","       -torch.mul(torch.matmul(a,V1),torch.mul(V2,torch.matmul(G_line,torch.cos(theta1 - theta2))\\\n","                                              -torch.matmul(B_line,torch.sin(theta1 - theta2))))\n","  f_q =-torch.mul(torch.matmul(a,B_line+B_shunt),torch.mul(V1,V1)) \\\n","       +torch.mul(torch.matmul(a,V1),torch.mul(V2,torch.matmul(B_line,torch.cos(theta1 - theta2))\\\n","                                              -torch.matmul(G_line,torch.sin(theta1 - theta2))))\n","  s_pred = torch.sqrt(torch.mul(f_p,f_p)+torch.mul(f_q,f_q)) * 100\n","  # sigmoid\n","  s_penalty = torch.sigmoid(s_pred-s_max) + torch.sigmoid(-s_pred-s_max)\n","  return s_penalty\n","\n","def s_feas_reg(train_batch,pred_label,v_pred,binary_thres,s_max,G_line,B_line,B_shunt,Br_inv,a):#, \\f_p,f_q,s_pred):\n","  label1 = torch.squeeze(pred_label,1).transpose(0,1) # LMP: 118*batch \n","  p_max=train_batch[:,0,:].transpose(0,1) - train_batch[:,1,:].transpose(0,1)\n","  quadratic_b=train_batch[:,4,:].transpose(0,1)\n","  quadratic_a=train_batch[:,5,:].transpose(0,1)\n","  quadratic_center=(label1-quadratic_b)/(quadratic_a+1e-10)/2\n","  gen_pred_binary = gen_pred_binary_cell(quadratic_center,p_max)\n","  p_inj=gen_pred_binary\n","  bus_inj = p_inj + train_batch[:,1,:].transpose(0,1)\n","  p_inj_r = torch.cat((bus_inj[:639,:],bus_inj[640:,:])) / 100 # remove ref bus and to p.u., bus 69\n","  \n","  theta0 = torch.matmul(Br_inv,p_inj_r) # approx bus angle w/ DC model\n","  ref_ang=torch.zeros(1,theta0.shape[1]).to(device)\n","  theta = torch.cat([theta0[:639,:],ref_ang,theta0[639:,:]],0) # insert, like np.insert\n","  v_pred = v_pred.transpose(0,1) / 100 + 0.8 # rescale to p.u.\n","  theta1 = theta[line_loc[:,0]-1,:]\n","  theta2 = theta[line_loc[:,1]-1,:]\n","  V1 = (v_pred[line_loc[:,0]-1,:]).double()\n","  V2 = (v_pred[line_loc[:,1]-1,:]).double() \n","\n","  pij_test=torch.zeros(20,5)\n","  qij_test=torch.zeros(20,5)\n","  for i in range(20):\n","    for j in range(5):\n","      pij_test[i,j]=a[i] * V1[i,j] * V1[i,j] * G_line[i] \\\n","              - (a[i] * V1[i,j]) * V2[i,j] \\\n","              * (G_line[i] * torch.cos(theta1[i,j] - theta2[i,j]) \\\n","                + B_line[i] * torch.sin(theta1[i,j] - theta2[i,j]))\n","      qij_test[i,j]=-(a[i] * V1[i,j]) **2 * (B_line[i] + B_shunt[i]/2) \\\n","              + a[i] * V1[i,j] * V2[i,j] \\\n","              * (B_line[i] * torch.cos(theta1[i,j] - theta2[i,j]) \\\n","                - G_line[i] * torch.sin(theta1[i,j] - theta2[i,j]))\n","\n","  f_p=(a*G_line*(V1*V1).T)-a*((V1*V2).T)*(G_line*torch.cos(theta1-theta2).T+B_line*torch.sin(theta1-theta2).T)\n","  f_p=f_p.T\n","  f_q=-a*(V1.T)*(a*V1.T)*(B_line+B_shunt/2)+a*((V1*V2).T)*(B_line*torch.cos(theta1-theta2).T-G_line*torch.sin(theta1-theta2).T)\n","  f_q=f_q.T\n","\n","  print('pij: \\n',pij_test)\n","  print('fpij: \\n',f_p[:20,:5])\n","  print('qij: \\n',qij_test)\n","  print('fqij: \\n',f_q[:20,:5])\n","  xx\n","\n","  s_pred = torch.sqrt(f_p*f_p+f_q*f_q)*100\n","  s_penalty = torch.sigmoid(s_pred-s_max) + torch.sigmoid(-s_pred-s_max)\n","  return s_penalty\n","\n","# define loss function\n","loss_func=nn.MSELoss()\n","def my_loss_func(pred,label,W1,train_batch,s_max,G_line,B_line,B_shunt,Br_inv,a):#,\\f_p,f_q,s_pred):\n","  lmda1=torch.from_numpy(np.array([1])).to(device) # L_2\n","  lmda2=torch.from_numpy(np.array([0.01])).to(device) # L_inf\n","  lmda4=torch.from_numpy(np.array([0.1])).to(device) # f-feasibility\n","\n","  binary_thres = 0.97 # P_g threshold for 0\n","  binary_thres = torch.tensor(binary_thres).to(device)\n","  mse_v = loss_func(pred[:,1,:],label[:,1,:]) \n","  mse_pi = loss_func(pred[:,0,:],label[:,0,:])\n","  linf_v = (pred[:,1,:]-label[:,1,:]).norm(p=float('inf'))\n","  linf_pi = (pred[:,0,:]-label[:,0,:]).norm(p=float('inf'))\n","  s_penalty = s_feas_reg(train_batch,pred[:,0,:],pred[:,1,:],binary_thres,s_max,G_line,B_line,B_shunt,Br_inv,a)#,\\f_p,f_q,s_pred) # scaled for S_ij\n","  sji_penalty = sji_feas_reg(train_batch,pred[:,0,:],pred[:,1,:],binary_thres,s_max,G_line,B_line,B_shunt,Br_inv,a)#,\\f_p,f_q,s_pred) # scaled for S_ij\n","  return lmda1*mse_v+lmda1*mse_pi+lmda2*linf_v+lmda2*linf_pi+lmda4*torch.sum(s_penalty)+lmda4*torch.sum(sji_penalty) #+lmda3*torch.mean(locality) # mean/sum over batch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iu0PKvcgF2vN"},"outputs":[],"source":["## Training\n","t0=time.time()\n","max_epochs=1\n","eval_epoch=5\n","\n","# earlystopping\n","tolerance=5\n","min_delta=1e-3\n","previous=0\n","\n","W_tensor = torch.from_numpy(W).float().to(device)\n","for epoch in range(max_epochs):\n","  # training loop\n","  train_loss=0.0\n","  for local_batch,local_label in training_generator:\n","    optimizer.zero_grad() # clear the past gradient\n","    logits=net(local_batch)\n","    loss=my_loss_func(logits,local_label,W_tensor,local_batch,f_max, \\\n","                      G_line_tensor,B_line_tensor,B_shunt_tensor,Br_inv_tensor,a_tensor)#, \\f_p,f_q,s_pred)\n","    loss.backward()\n","    train_loss+=loss.item()\n","    optimizer.step() # update parameters of net\n","  loss_optm.append(train_loss/len(training_generator.dataset))\n","  print(\"Epoch %d | Training loss: %.4f\"%(epoch,train_loss/len(training_generator.dataset)))\n","  # eval\n","  if (epoch+1)%eval_epoch==0:\n","    net.eval()\n","    eval_loss=0.0\n","    for eval_batch,eval_label in validation_generator:\n","      eval_batch,eval_label=eval_batch.to(device),eval_label.to(device)\n","      logits=net(eval_batch)\n","      loss=my_loss_func(logits,eval_label,W_tensor,eval_batch,f_max,\\\n","                        G_line_tensor,B_line_tensor,B_shunt_tensor,Br_inv_tensor,a_tensor)\n","      eval_loss+=loss.item()\n","    eval_avg=eval_loss/len(validation_generator.dataset)\n","    if (epoch==0): previous=eval_avg\n","    else:\n","      if previous-eval_avg<min_delta: tolerance-=1\n","      if tolerance==0: break\n","      previous=eval_avg\n","    print(\"Epoch %d | Eval loss: %.4f\" % (epoch, eval_avg))\n","    loss_val.append([epoch, eval_loss/len(validation_generator.dataset)])\n","    net.train()\n","  # validation loop\n","  with torch.set_grad_enabled(False):\n","      pass\n","t1=time.time()\n","print(\"Training time:%.4fs\"%(t1-t0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AvUTphUSzqzA"},"outputs":[],"source":["# logits[0:2,:,:]\n","# W\n","path='data_1354ac_2022/feasgnn_trained_ac1354_03142022.pickle'\n","torch.save(net.state_dict(),path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0xKjXKFOKf4n"},"outputs":[],"source":["# print(len(loss_val))\n","# print(loss_val[0][0])\n","# # print(val_plt)\n","# print(logits.shape,eval_label.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L3M4jmjkscK_"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","val_len = len(loss_val)\n","print(val_len)\n","val_plt = np.zeros((2,val_len))\n","for i in range(val_len):\n","  val_plt[0,i] = loss_val[i][0]\n","  val_plt[1,i] = loss_val[i][1]\n","\n","plt.figure()\n","plot_idx = np.arange(np.size(loss_optm))\n","# plt.plot(plot_idx,loss_optm,lw=2,label='training loss')\n","# plt.plot(val_plt[0,:],val_plt[1,:],lw=2,label='validation loss')\n","plt.plot(plot_idx[5:-1],loss_optm[5:-1],lw=2,label='training loss')\n","plt.plot(val_plt[0,1:],val_plt[1,1:],lw=2,label='validation loss')\n","plt.yscale(\"log\")\n","plt.xlabel('epoch')\n","plt.ylabel('loss')\n","plt.legend()\n","plt.show(block=False)\n","\n","# from datetime import datetime\n","# now=datetime.now()\n","# timestamp=now.strftime('%Y%d%m%H%M%S')\n","# path='/content/drive/MyDrive/gnn/dnn_pytorch/gnn_%s.pickle'%(timestamp)\n","# # torch.save(net.state_dict(),path)\n","# path='/content/drive/MyDrive/gnn/dnn_pytorch/gnn_118_%s.pickle'%(timestamp)\n","# torch.save(net.state_dict(),path)\n","# path = '/content/drive/MyDrive/gnn/dnn_pytorch/gnn_118_20212205071835.pickle'\n","# net.load_state_dict(torch.load(path))"]},{"cell_type":"markdown","metadata":{"id":"R9uGUm4rsco3"},"source":["# Evaluate the model w/ validation set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rkj81aqpVS0j"},"outputs":[],"source":["# local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n","# print(local_batch.shape)\n","# x_test_feed = x_test_feed.unsqueeze_(-1).transpose(1,2)\n","# print(x_test_feed.shape)\n","\n","# print(local_batch.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4u6001UQ2pN3"},"outputs":[],"source":["# validation_set = Dataset(features=x_test, labels=y_test)\n","# validation_generator = torch.utils.data.DataLoader(validation_set, **params)\n","# for local_batch, local_labels in validation_generator:\n","#   # Transfer to GPU\n","#   local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n","#   logits = net(local_batch)\n","\n","n_test = 2000\n","\n","x_test_feed = torch.from_numpy(np.transpose(x_test)).float()\n","x_test_feed = x_test_feed#.transpose(1,2)\n","x_test_feed = x_test_feed.to(device)\n","print('Validation dataset size:',x_test_feed.shape)\n","print('Number of validation set: ',n_test)\n","# y_pred = np.zeros((x_test_feed.shape))\n","# for i in range(n_test):\n","#   y_pred[i,:] = net(x_test_feed[i,:])\n","y_pred = net(x_test_feed)"]},{"cell_type":"markdown","metadata":{"id":"YnNbSGYoXS3J"},"source":["* Visualization\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"VKZQaqwJkn3P"},"source":[" - Visualize errors"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7-JCo0KmXwm3"},"outputs":[],"source":["y_pred1 = y_pred.cpu().detach()\n","y_pred1 = torch.squeeze(y_pred1,1).numpy().transpose()\n","print(y_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2eVE-t3nl0Cb"},"outputs":[],"source":["# recover the original p.u. scale\n","y_pred1 = y_pred1 / 100 + 0.8\n","y_test = y_test / 100 + 0.8\n","\n","print(y_test.shape,y_pred1.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hXy9bUnqE-Qs"},"outputs":[],"source":["# for i in range(5):\n","#   print('sample',i)\n","#   print(y_test[:,i])\n","#   print(y_pred1[:,i])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FUVl5LXeknC4"},"outputs":[],"source":["n_test = np.size(y_test,2)\n","err_L2 = np.zeros(n_test)\n","err_Linf = np.zeros(n_test)\n","for i in range(n_test):\n","  err_L2[i] = np.linalg.norm(y_test[:,0,i] - y_pred1[:,0,i]) / np.linalg.norm(y_test[:,0,i])\n","  err_Linf[i] = np.max(np.abs(y_test[:,0,i] - y_pred1[:,0,i])) / np.max(np.abs(y_test[:,0,i]))\n","\n","err_L2_v = np.zeros(n_test)\n","err_Linf_v = np.zeros(n_test)\n","for i in range(n_test):\n","  err_L2_v[i] = np.linalg.norm(y_test[:,1,i] - y_pred1[:,1,i]) / np.linalg.norm(y_test[:,1,i])\n","  err_Linf_v[i] = np.max(np.abs(y_test[:,1,i] - y_pred1[:,1,i])) / np.max(np.abs(y_test[:,1,i]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4K1fxmcGqvC9"},"outputs":[],"source":["print(err_L2.shape,err_Linf.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"79xFCVXklkLb"},"outputs":[],"source":["err_L2_mean = np.mean(err_L2)\n","err_Linf_mean = np.mean(err_Linf)\n","print('Price L2 mean:', err_L2_mean,'L_inf mean:', err_Linf_mean )\n","err_L2_mean_v = np.mean(err_L2_v)\n","err_Linf_mean_v = np.mean(err_Linf_v)\n","print('Voltage L2 mean:', err_L2_mean_v,'L_inf mean:', err_Linf_mean_v )\n","\n","fig2 = plt.figure(figsize=(16, 16))\n","plt.subplot(2, 2, 1)\n","# plt.hist(np.abs(ga),bins = 10)\n","plt.plot(err_L2,'bo',markersize=0.5,label = 'L2 error')\n","plt.plot(err_Linf,'r^',markersize=0.5,label = 'Linf error')\n","plt.legend(loc=\"upper right\")\n","plt.xlabel('sample index')\n","plt.ylabel('error')\n","plt.title('Normalized sample error')\n","plt.grid(True)\n","# error histogram\n","plt.subplot(2, 2, 2)\n","plt.hist(err_L2, bins = 50, facecolor='b', alpha=0.75,label = 'L2 error')\n","plt.hist(err_Linf, bins = 50, facecolor='g', alpha=0.75,label = 'Linf error')\n","plt.legend(loc=\"upper right\")\n","plt.xlabel('sample error value')\n","plt.ylabel('frequency')\n","plt.title('Histogram of L_2 error')\n","# plt.text(60, .025, r'$\\mu=100,\\ \\sigma=15$')\n","plt.grid(True)\n","\n","plt.subplot(2, 2, 3)\n","# plt.hist(np.abs(ga),bins = 10)\n","plt.plot(err_L2_v,'bo',markersize=0.5,label = 'L2 error')\n","plt.plot(err_Linf_v,'r^',markersize=0.5,label = 'Linf error')\n","plt.legend(loc=\"upper right\")\n","plt.xlabel('sample index')\n","plt.ylabel('error')\n","plt.title('Normalized sample error')\n","plt.grid(True)\n","# error histogram\n","plt.subplot(2, 2, 4)\n","plt.hist(err_L2_v, bins = 50, facecolor='b', alpha=0.75,label = 'L2 error')\n","plt.hist(err_Linf_v, bins = 50, facecolor='g', alpha=0.75,label = 'Linf error')\n","plt.legend(loc=\"upper right\")\n","plt.xlabel('sample error value')\n","plt.ylabel('frequency')\n","plt.title('Histogram of L_2 error')\n","# plt.text(60, .025, r'$\\mu=100,\\ \\sigma=15$')\n","plt.grid(True)\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6sUddh-uGg_p"},"outputs":[],"source":["print(y_pred1[:,1,:n_test].shape,y_test[:,1,:n_test].shape)\n","print('t        an:',np.max(y_test[:,1,:n_test]),np.min(y_test[:,1,:n_test]))\n","print('p   dicd     an',np.max(y_pred1[:,1,:n_test]),np.min(y_pred1[:,1,:n_test]))\n","\n","fig3 = plt.figure(figsize=(16, 8))\n","flat_list1 = list(np.concatenate(y_test[:,1,:n_test]).flat)\n","flat_list2 = list(np.concatenate(y_pred1[:,1,:n_test]).flat)\n","plt.hist(flat_list1,bins = 100,label = 'true')\n","\n","plt.hist(flat_list2,bins = 100,label = 'pred')\n","plt.legend(loc=\"upper right\")\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HxizRhz5OVpW"},"outputs":[],"source":["err_l2_new = [i for i in err_L2 if i < 1]\n","err_linf_new = [i for i in err_Linf if i < 1]\n","print(len(err_l2_new),'L2 mean:', np.mean(err_l2_new),len(err_linf_new),'L_inf mean:', np.mean(err_linf_new) )\n","\n","fig2 = plt.figure(figsize=(16, 8))\n","plt.subplot(1, 2, 1)\n","# plt.hist(np.abs(ga),bins = 10)\n","plt.plot(err_l2_new,'bo',markersize=0.5,label = 'L2 error')\n","plt.plot(err_linf_new,'r^',markersize=0.5,label = 'Linf error')\n","plt.legend(loc=\"upper right\")\n","plt.xlabel('sample index')\n","plt.ylabel('error')\n","plt.title('Normalized sample error w/out >1')\n","plt.grid(True)\n","# error histogram\n","plt.subplot(1, 2, 2)\n","plt.hist(err_l2_new, bins = 50, facecolor='b', alpha=0.75,label = 'L2 error')\n","plt.hist(err_linf_new, bins = 50, facecolor='g', alpha=0.75,label = 'Linf error')\n","plt.legend(loc=\"upper right\")\n","plt.xlabel('sample error value')\n","plt.ylabel('frequency')\n","plt.title('Histogram of L_2 error  w/out >1')\n","# plt.text(60, .025, r'$\\mu=100,\\ \\sigma=15$')\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TY5VfIy1PKQO"},"outputs":[],"source":["print(x_train.shape)\n","# print(x_train[:,:,1].transpose())\n","# print(np.max(gen_limit0),np.min(err_linf_new))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jhfImaPsjKYq"},"outputs":[],"source":["# y_test_copy\n","# y_pred1[:,index]"]},{"cell_type":"markdown","metadata":{"id":"H9x7neMNj7n3"},"source":["# Predict generation using $\\pi$\n","* Using predicted $\\pi$ and find the active constraints in $p_G(i)$\n","* For inactive $p_G(i)$ consider other methods like power flow balance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kr29K04j2KTN"},"outputs":[],"source":["gen_limit0 = x[:,4,:].copy() # lin cost\n","print(gen_limit0.shape)\n","\n","gen_idx = []\n","gen_idx = np.arange(n_bus)\n","# for i in range(n_bus):\n","#   if gen_limit0[i,0] > 0:\n","#     gen_idx.append(i)\n","print(type(gen_idx),len(gen_idx),gen_idx)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7LUcg6DDk13A"},"outputs":[],"source":["# # get the generator index\n","# # generator cost data\n","# gen_cost0\n","# # generator limit data\n","# gen_limit0\n","# # LMP data\n","# lmp_data\n","# # generation data\n","# gen_data\n","\n","load_data = x.copy()\n","load_data = load_data[:,:]\n","print(load_data.shape)\n","n_sample = np.size(load_data,2)\n","\n","# predict the corredponding LMP\n","x_val_feed = torch.from_numpy(np.transpose(load_data)).float()\n","batch_size=2000\n","y_pred1=[]\n","with torch.no_grad():\n","  for idx in range(0,x_val_feed.shape[0],batch_size):\n","    current_batch=x_val_feed[idx:idx+batch_size]\n","    current_batch=current_batch.to(device)\n","    current_y=net(current_batch)\n","    current_y=current_y.cpu().detach()\n","    current_y=torch.squeeze(current_y,1).numpy().tolist()\n","    y_pred1+=current_y\n","y_pred1=np.array(y_pred1).transpose()\n","\n","print('Dataset size:',x_val_feed.shape)\n","print('Number of validation points:: ',n_sample)\n","\n","# net1 = net.cpu()\n","# y_pred = net1(x_val_feed)\n","\n","# y_pred1 = y_pred.cpu().detach()\n","print('output size',y_pred1.shape)\n","# y_pred1 = torch.squ[]eeze(y_pred1,1).numpy().transpose()\n","print('reshaped size',y_pred1.shape)\n","\n","# load_data = x.copy()\n","# print(load_data.shape)\n","# n_sample = np.size(load_data,2)\n","\n","# x_val_feed = torch.from_numpy(np.transpose(load_data)).float()\n","# x_val_feed = x_val_feed.to(device)\n","\n","# print('Dataset size:',x_val_feed.shape)\n","# print('Number of validation points:: ',n_sample)\n","# y_pred = net(x_val_feed) # predict the corredponding LMP\n","\n","# y_pred1 = y_pred.cpu().detach()\n","# print('output size',y_pred1.shape)\n","# y_pred1 = torch.squeeze(y_pred1,1).numpy().transpose()\n","# print('reshaped size',y_pred1.shape)"]},{"cell_type":"markdown","metadata":{"id":"DIMUWHsL5tdd"},"source":["* Save results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0GrY62p56Srd"},"outputs":[],"source":["import pickle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EeDi2jga6eON"},"outputs":[],"source":["# dataset = {'lmp_pred': y_pred1, 'lmp_true': lmp_data}\n","# print('Pred:',y_pred1.shape,'True:',lmp_data.shape)\n","\n","# file_name = 'dc118_lmp_prediction_p10'\n","# file_path = 'drive/My Drive/gnn/data/results/'\n","# file_dir = file_path + file_name + '.pickle'\n","# outfile = open(file_dir, 'wb')\n","# pickle.dump(dataset, outfile)\n","# outfile.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GPEHF2L91bGv"},"outputs":[],"source":["gen_cost0 = x[:,4,:].copy()\n","lmp_data = y[:,0,:].copy()\n","\n","quadratic_a = x[:,5,:].copy()\n","\n","profit_pred = y_pred1[:,0,:] - gen_cost0\n","print(np.min(np.abs(profit_pred)))\n","\n","profit_true = lmp_data - gen_cost0\n","print(np.min(np.abs(profit_true)))\n","\n","profit_pred=(y_pred1[:,0,:]-gen_cost0)/(quadratic_a+1e-10)/2\n","profit_true=(lmp_data-gen_cost0)/(quadratic_a+1e-10)/2\n","print(np.min(np.abs(profit_pred)))\n","print(np.min(np.abs(profit_true)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uiHWtU5OLc1x"},"outputs":[],"source":["print(profit_pred.shape,profit_true.shape)\n","profit_err = profit_true - profit_pred\n","\n","profit_err_l2 = np.zeros([n_sample,1])\n","\n","for i in range(n_sample):\n","  profit_err_l2[i] = np.linalg.norm(profit_err[:,i])/np.linalg.norm(profit_true[:,i])\n","print(np.mean(profit_err_l2))\n","\n","fig5 = plt.figure(figsize=(16, 8))\n","# error histogram\n","plt.hist(profit_err_l2, bins = 50, facecolor='b', alpha=0.75,label = 'L2 error')\n","# plt.hist(err_linf_new, bins = 50, facecolor='g', alpha=0.75,label = 'Linf error')\n","plt.legend(loc=\"upper right\")\n","plt.xlabel('sample error value')\n","plt.ylabel('frequency')\n","plt.title('Histogram of L_2 error')\n","# plt.text(60, .025, r'$\\mu=100,\\ \\sigma=15$')\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZbHchRQd_g8-"},"outputs":[],"source":["p_pred_sort = np.reshape(profit_pred,n_bus*n_sample)\n","p_true_sort = np.reshape(profit_true,n_bus*n_sample)\n","print(p_pred_sort.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ozJmJygjBLVX"},"outputs":[],"source":["print(np.min(p_pred_sort),np.min(p_true_sort))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TYsSdNGp-OLP"},"outputs":[],"source":["fig2 = plt.figure(figsize=(8, 8))\n","plt.hist(p_pred_sort, bins = 50, facecolor='b', alpha=0.75,label = 'pred. profit')\n","plt.hist(p_true_sort, bins = 50, facecolor='g', alpha=0.75,label = 'true profit')\n","plt.legend(loc=\"upper right\")\n","plt.xlabel('value')\n","plt.ylabel('frequency')\n","plt.title('profit histogram')\n","# plt.text(60, .025, r'$\\mu=100,\\ \\sigma=15$')\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EHWY5moJ6gin"},"outputs":[],"source":["# gen_pred_binary = np.zeros((len(gen_idx),n_sample))\n","# gen_true_binary = np.zeros((len(gen_idx),n_sample))\n","# print(gen_pred_binary.shape)\n","\n","# binary_thres = 2.5\n","# binary_thres_true = 1e-5\n","\n","# for i in range(n_sample):\n","#   for j in range(len(gen_idx)):\n","#     # predicted generator limit\n","#     if profit_pred[gen_idx[j],i] > binary_thres:\n","#       gen_pred_binary[j,i] = 1\n","#     elif profit_pred[gen_idx[j],i] < 0:\n","#       gen_pred_binary[j,i] = 0\n","#     else:\n","#       # gen_pred_binary[j,i] = (profit_pred[gen_idx[j],i] + binary_thres) / (2*binary_thres)\n","#       gen_pred_binary[j,i] = (profit_pred[gen_idx[j],i]) / (binary_thres)\n","#     # true generator limit\n","#     if profit_true[gen_idx[j],i] > binary_thres_true:\n","#       gen_true_binary[j,i] = 1\n","#     elif profit_true[gen_idx[j],i] < 0:\n","#       gen_true_binary[j,i] = 0\n","#     else:\n","#       gen_true_binary[j,i] = 0.5\n","\n","# gen_binary_err = np.abs(gen_true_binary - gen_pred_binary)\n","# print('max binary error:',np.max(gen_binary_err))\n","# # count the wrong entries\n","# gen_binary_err_ct = np.sum(gen_binary_err)\n","# gen_binary_err_ratio = gen_binary_err_ct / (len(gen_idx)*n_sample)\n","# print('Binary accuracy:',1-gen_binary_err_ratio)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nnNXdj-v6-7I"},"outputs":[],"source":["print(gen_limit0.shape)\n","print(np.transpose(x_test).shape,np.transpose(load_data).shape)"]},{"cell_type":"markdown","metadata":{"id":"O3QpqC6OjSXe"},"source":[" # Test flow feasibility"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P5S-SMQJwVoA"},"outputs":[],"source":["x[:,2,:].shape\n","profit_pred.shape\n","# n_sample"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1J9j5tT9p_f6"},"outputs":[],"source":["# x = [load, gen_cost, gen_lim]\n","\n","# binary_thres = 0.97\n","binary_thres_true = 1e-5\n","# binary_thres = gen_limit0\n","binary_thres = x[:,0,:].copy() # upper\n","binary_thres_lo = x[:,1,:].copy() # lower\n","\n","gen_pred_binary_full = np.zeros((n_bus,n_sample))\n","gen_true_binary_full = np.zeros((n_bus,n_sample))\n","# print(gen_pred_binary.shape,profit_pred.shape,gen_pred_binary_full.shape)\n","\n","# x[:,2,:] # p_max\n","\n","# ## generator injection\n","# for i in range(n_sample):\n","#   for j in range(len(gen_idx)):\n","#     # predicted generator limit\n","#     if profit_pred[gen_idx[j],i] > binary_thres[gen_idx[j],i]:\n","#       gen_pred_binary_full[gen_idx[j],i] = binary_thres[gen_idx[j],i]\n","#     elif profit_pred[gen_idx[j],i] < 0:\n","#       gen_pred_binary_full[gen_idx[j],i] = 0\n","#     else:\n","#       gen_pred_binary_full[gen_idx[j],i] = profit_pred[gen_idx[j],i]\n","#     # true generator limit\n","#     if profit_true[gen_idx[j],i] > binary_thres[gen_idx[j],i]:\n","#       gen_true_binary_full[gen_idx[j],i] = binary_thres[gen_idx[j],i]\n","#     elif profit_true[gen_idx[j],i] < 0:\n","#       gen_true_binary_full[gen_idx[j],i] = 0\n","#     else:\n","#       gen_true_binary_full[gen_idx[j],i] = profit_true[gen_idx[j],i]\n","\n","## nodal injection\n","# gen_limit0 = x[:,2,:].copy()\n","for i in range(n_sample):\n","  for j in range(len(gen_idx)):\n","    # predicted generator limit\n","    if profit_pred[gen_idx[j],i] > binary_thres[gen_idx[j],i]:\n","      gen_pred_binary_full[gen_idx[j],i] = binary_thres[gen_idx[j],i]\n","    elif profit_pred[gen_idx[j],i] < binary_thres_lo[gen_idx[j],i]:\n","      gen_pred_binary_full[gen_idx[j],i] = binary_thres_lo[gen_idx[j],i]\n","    else:\n","      gen_pred_binary_full[gen_idx[j],i] = profit_pred[gen_idx[j],i]\n","    # true generator limit\n","    if profit_true[gen_idx[j],i] > binary_thres[gen_idx[j],i]:\n","      gen_true_binary_full[gen_idx[j],i] = binary_thres[gen_idx[j],i]\n","    elif profit_true[gen_idx[j],i] < binary_thres_lo[gen_idx[j],i]:\n","      gen_true_binary_full[gen_idx[j],i] = binary_thres_lo[gen_idx[j],i]\n","    else:\n","      gen_true_binary_full[gen_idx[j],i] = profit_true[gen_idx[j],i]\n","\n","\n","# injection by generators\n","# gen_inj = np.multiply(gen_pred_binary_full,gen_limit0)\n","# gen_inj_true = np.multiply(gen_true_binary_full,gen_limit0)\n","gen_inj=gen_pred_binary_full\n","gen_inj_true=gen_true_binary_full\n","# nodal injection\n","load0 = -x[:,1,:].copy() # load file\n","p_inj = gen_inj #- load0\n","p_inj_true = gen_inj_true #- load0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-12s6DdnrDvo"},"outputs":[],"source":["# load0 = x[:,0,:].copy()\n","print(np.sum(p_inj),np.sum(gen_inj_true))\n","print(np.sum(p_inj),np.sum(load0),np.sum(gen_inj))"]},{"cell_type":"markdown","metadata":{"id":"WAgqdRPjAONm"},"source":["## injection accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J46pLAw2AQor"},"outputs":[],"source":["print(p_inj_true.shape,p_inj.shape)\n","\n","p_inj_true_sort = np.reshape(p_inj_true,n_bus*n_sample)\n","p_inj_sort = np.reshape(p_inj,n_bus*n_sample)\n","\n","p_err = np.zeros(n_sample)\n","for i in range(n_sample):\n","  p_err[i] = np.linalg.norm(p_inj_true[:,i]-p_inj[:,i]) / np.linalg.norm(p_inj_true[:,i])\n","\n","print('mean p_inj l2 err:',np.mean(p_err))\n","fig3 = plt.figure(figsize=(16, 8))\n","plt.subplot(1,2,1)\n","plt.hist(p_inj_sort, bins = 50, facecolor='b', alpha=0.75,label = 'pred. injection')\n","plt.hist(p_inj_true_sort, bins = 50, facecolor='g', alpha=0.75,label = 'true injection')\n","plt.legend(loc=\"upper right\")\n","plt.xlabel('value')\n","plt.ylabel('frequency')\n","plt.title('injection histogram')\n","plt.subplot(1,2,2)\n","plt.hist(p_err, bins = 50, facecolor='b', alpha=0.75,label = 'injection err')\n","plt.legend(loc=\"upper right\")\n","plt.xlabel('value')\n","plt.ylabel('frequency')\n","plt.title('error histogram')\n","# plt.text(60, .025, r'$\\mu=100,\\ \\sigma=15$')\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"DaN7u4xeGIom"},"source":["* Calculate flow"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YT4sgn_n79MI"},"outputs":[],"source":["n_line = np.size(S_isf,0)\n","flow_est = np.zeros((n_line,n_sample))\n","flow_est0 = np.zeros((n_line,n_sample))\n","\n","f_binary = np.zeros((n_line,n_sample))\n","f_binary0 = np.zeros((n_line,n_sample))\n","\n","# for i in range(n_sample):\n","flow_est = np.dot(S_isf,p_inj)\n","flow_est0 = np.dot(S_isf,p_inj_true)\n","# f_max\n","f_max_numpy = f_max.cpu().detach().numpy()\n","f_binary = (np.abs(flow_est)-f_max_numpy > 0)\n","f_binary0 = (np.abs(flow_est0)-f_max_numpy > 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"akXhlvIeKYDQ"},"outputs":[],"source":["f_tot_sample = n_line * n_sample\n","print(np.sum(f_binary),np.sum(f_binary0))\n","print(np.sum(f_binary)/f_tot_sample,np.sum(f_binary0)/f_tot_sample)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VDUoE22I4eRm"},"outputs":[],"source":["print(n_line,n_sample,flow_est.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VyvDpKhyQj0M"},"outputs":[],"source":["# soft threshold\n","f_err_est = np.abs(flow_est)-f_max_numpy\n","f_err_true = np.abs(flow_est0)-f_max_numpy\n","\n","f_err_est = np.maximum(np.abs(flow_est)-f_max_numpy,0) # identify violations\n","f_err_true = np.maximum(np.abs(flow_est0)-f_max_numpy,0)\n","\n","print(np.max(f_err_est),np.max(f_err_true))\n","print(np.max(f_err_est/f_max_numpy),np.max(f_err_true/f_max_numpy))\n","\n","# a= np.asarray([[1,2,1],[2,2,1]])\n","# b = np.asarray([1,1,1])\n","# c = (a-b>0)\n","# print(c)\n","# print(np.sum(c))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K2vXlUEXdwm0"},"outputs":[],"source":["np.min(f_max_numpy)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7iuX7tN2a2Cp"},"outputs":[],"source":["# f_binary_soft = (np.abs(flow_est)-f_max_numpy > 0.01*np.max(f_max_numpy))\n","# f_binary0_soft = (np.abs(flow_est0)-f_max_numpy > 0.01*np.max(f_max_numpy))\n","f_binary_soft = (np.abs(flow_est)-f_max_numpy > 0.1*(f_max_numpy))\n","f_binary0_soft = (np.abs(flow_est0)-f_max_numpy > 0.1*(f_max_numpy))\n","print(np.sum(f_binary_soft),np.sum(f_binary0_soft))\n","print(np.sum(f_binary_soft)/f_tot_sample,np.sum(f_binary0_soft)/f_tot_sample)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SYl9pxnOUUQF"},"outputs":[],"source":["f_pred_sort = np.reshape(f_err_est/f_max_numpy,n_line*n_sample)\n","f_true_sort = np.reshape(f_err_true/f_max_numpy,n_line*n_sample)\n","\n","fig2 = plt.figure(figsize=(16, 8))\n","plt.subplot(1,2,1)\n","plt.hist(f_pred_sort, bins = 10, facecolor='b', alpha=0.75,label = 'pred. f')\n","plt.hist(f_true_sort, bins = 10, facecolor='g', alpha=0.75,label = 'true f')\n","plt.legend(loc=\"upper right\")\n","plt.xlabel('percentage')\n","plt.ylabel('frequency')\n","plt.title('flow violation level histogram')\n","plt.subplot(1,2,2)\n","plt.hist(f_true_sort, bins = 10, facecolor='g', alpha=0.75,label = 'true f')\n","plt.legend(loc=\"upper right\")\n","plt.xlabel('percentage')\n","plt.ylabel('frequency')\n","plt.title('flow violation level histogram')\n","# plt.text(60, .025, r'$\\mu=100,\\ \\sigma=15$')\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YglgTpWVRLri"},"outputs":[],"source":["f_line = np.sum(f_binary,0)\n","f_samp = np.sum(f_binary,1)\n","print('max sample pred:',np.max(f_line))\n","print('max line pred:',np.max(f_samp))\n","\n","f_line0  = np.sum(f_binary0,0)\n","f_samp0 = np.sum(f_binary0,1)\n","print('max sample true:',np.max(f_line0))\n","print('max line true:',np.max(f_samp0))"]},{"cell_type":"markdown","metadata":{"id":"WZQnarHmPl35"},"source":["# Check objective optimality"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uzvirohf8NSh"},"outputs":[],"source":["# gen_pred_binary_full = np.zeros((n_bus,n_sample))\n","# gen_true_binary_full = np.zeros((n_bus,n_sample))\n","\n","# p_inj = gen_inj #- load0\n","# p_inj_true = gen_inj_true #- load0\n","\n","# gen_cost0 = x[:,4,:].copy()\n","# # lmp_data = y.copy()\n","\n","# quadratic_a = x[:,5,:].copy()\n","print(gen_cost0.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BZjhp-CgQaDz"},"outputs":[],"source":["gen_cost_pred = np.zeros((n_bus,n_sample))\n","gen_cost_true = np.zeros((n_bus,n_sample))\n","objective_err = np.zeros(n_sample)\n","\n","gen_cost_pred = np.multiply(np.multiply(p_inj,p_inj),quadratic_a) + np.multiply(p_inj,gen_cost0)\n","gen_cost_true = np.multiply(np.multiply(p_inj_true,p_inj_true),quadratic_a) + np.multiply(p_inj_true,gen_cost0)\n","\n","objective_err = np.sum(np.abs(gen_cost_true-gen_cost_pred),axis=0) / np.sum(gen_cost_true,axis=0)\n","print(np.mean(objective_err))\n","\n","fig6 = plt.figure(figsize=(16, 8))\n","# error histogram\n","plt.hist(objective_err, bins = 50, facecolor='b', alpha=0.75,label = 'L2 error')\n","# plt.hist(err_linf_new, bins = 50, facecolor='g', alpha=0.75,label = 'Linf error')\n","plt.legend(loc=\"upper right\")\n","plt.xlabel('sample error value')\n","plt.ylabel('frequency')\n","plt.title('Histogram of L_2 error')\n","# plt.text(60, .025, r'$\\mu=100,\\ \\sigma=15$')\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R634kVOrR2lM"},"outputs":[],"source":["objective_err.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ewAUZuklSDEF"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"vdrsAWpYo0-w"},"source":["## injection accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mArjSN-So0-x"},"outputs":[],"source":["print(p_inj_true.shape,p_inj.shape)\n","\n","p_inj_true_sort = np.reshape(p_inj_true,n_bus*n_sample)\n","p_inj_sort = np.reshape(p_inj,n_bus*n_sample)\n","\n","p_err = np.zeros(n_sample)\n","for i in range(n_sample):\n","  p_err[i] = np.linalg.norm(p_inj_true[:,i]-p_inj[:,i]) / np.linalg.norm(p_inj_true[:,i])\n","\n","print('mean p_inj l2 err:',np.mean(p_err))\n","fig3 = plt.figure(figsize=(16, 8))\n","plt.subplot(1,2,1)\n","plt.hist(p_inj_sort, bins = 50, facecolor='b', alpha=0.75,label = 'pred. injection')\n","plt.hist(p_inj_true_sort, bins = 50, facecolor='g', alpha=0.75,label = 'true injection')\n","plt.legend(loc=\"upper right\")\n","plt.xlabel('value')\n","plt.ylabel('frequency')\n","plt.title('injection histogram')\n","plt.subplot(1,2,2)\n","plt.hist(p_err, bins = 50, facecolor='b', alpha=0.75,label = 'injection err')\n","plt.legend(loc=\"upper right\")\n","plt.xlabel('value')\n","plt.ylabel('frequency')\n","plt.title('error histogram')\n","# plt.text(60, .025, r'$\\mu=100,\\ \\sigma=15$')\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"da0VjEW3pObT"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"ujU84tOSpqsy"},"source":["# Test AC feasibility\n","* P in actual value, V in p.u.\n","* Use P to recover $\\theta$, or solve $\\theta$ and Q for PF\n","$$ Q_m = V_m \\sum_{n=1}^N V_n \\left(G_{mn}\\sin\\theta_{mn} - B_{mn}\\cos\\theta_{mn} \\right) $$\n","calculate $Q_{mn}$ directly"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J8weK7Cspsx7"},"outputs":[],"source":["# p_inj (base all 100), p=B\\theta, \\theta_r = B_r^-1 p_r, ref bus is 69\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Of6mEXF4puDN"},"outputs":[],"source":["# Bbus and B_r inverse\n","filename1 = 'data_1354ac_2022/ieee1354_Bbus.txt'\n","Bbus=pd.read_table(filename1,sep=',',header=None).to_numpy()\n","B_r = np.delete(Bbus,639,axis=0)\n","B_r = np.delete(B_r,639,axis=1)\n","\n","Br_inv = np.linalg.inv(B_r)\n","\n","# # Y = G + jB\n","# filename1 = 'data_1354ac_2022/ieee118_Gmat.txt'\n","# G_mat=pd.read_table(filename1,sep=',',header=None).to_numpy()\n","# filename1 = 'data_1354ac_2022/ieee118_Bmat.txt'\n","# B_mat=pd.read_table(filename1,sep=',',header=None).to_numpy()\n","# print(G_mat.shape,B_mat.shape)\n","\n","# line parameters\n","filename1 = 'data_1354ac_2022/ieee1354_lineloc.txt'\n","line_loc = pd.read_table(filename1,sep=',',header=None).to_numpy()\n","# line_entry_loc = np.nonzero(G_mat) # index of nonzero entries\n","# # not in p.u.\n","# G_line = np.zeros(n_line)\n","# B_line = np.zeros(n_line)\n","\n","# # print(line_loc.shape) #[186,2]\n","# for i in range(n_line):\n","#   G_line[i] = G_mat[line_loc[i,0]-1,line_loc[i,1]-1]\n","#   B_line[i] = B_mat[line_loc[i,0]-1,line_loc[i,1]-1]\n","\n","# load line params\n","filename1 = 'data_1354ac_2022/ieee1354_lineparams_tap.txt'\n","line_params = pd.read_table(filename1,sep=',',header=None).to_numpy()\n","\n","n_line = 1751 # the rest are transformers\n","line_loc = line_loc[:n_line,:].copy()\n","line_params = line_params[:n_line,:].copy()\n","\n","# filename2 = 'data_1354ac_2022/ieee1354_Ybus.txt'\n","# Y_bus = pd.read_table(filename2,sep=',',header=None).to_numpy()\n","\n","# G_line = line_params[:,0].copy()\n","# B_line = line_params[:,1].copy()\n","R_line = line_params[:,0].copy()\n","X_line = line_params[:,1].copy()\n","\n","B_shunt = line_params[:,2].copy()\n","\n","Z_line = R_line + 1j * X_line \n","Y_line = 1 / Z_line\n","\n","G_line = np.real(Y_line)\n","B_line = np.imag(Y_line)\n","\n","# P_inj w/out reference bus in p.u.\n","p_inj_r = np.delete(p_inj,639,axis=0) / 100\n","p_inj_true_r = np.delete(p_inj_true,639,axis=0) / 100\n","\n","p_inj_pu = p_inj / 100\n","p_inj_true_pu = p_inj_true / 100\n","\n","print(Br_inv.shape,p_inj.shape,p_inj_true.shape)#p_inj_true\n","\n","# calculate angle (w/our reference at 640th node)\n","theta0 = np.matmul(Br_inv,p_inj_r)\n","theta_true0 = np.matmul(Br_inv,p_inj_true_r)\n","\n","theta = np.insert(theta0,639,0,axis = 0)\n","theta_true = np.insert(theta_true0,639,0,axis = 0)\n","\n","# filename1 = '/content/drive/MyDrive/gnn/data/data_118_quad/ieee118_ac_10000_theta.txt'\n","# theta = pd.read_table(filename1,sep=',',header=None).to_numpy()\n","# theta = theta / 180 * math.pi\n","\n","print(theta.shape,theta_true.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5sIKgWl9D8yO"},"outputs":[],"source":["for i in range(5):\n","  print(G_line[i],B_line[i])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OZ8ARinzuBqZ"},"outputs":[],"source":["print(np.max(theta),np.min(theta))\n","# math.sin(math.pi/6)\n","print(G_line[0],B_line[0])\n","\n","\n","# print(Y_bus.shape,line_loc.shape,G_line.shape,n_line)\n","\n","# G_line1 = np.zeros(n_line)\n","# B_line1 = np.zeros(n_line)\n","\n","# for i in range(2):\n","#   Y_temp = Y_bus[line_loc[i,0]-1,line_loc[i,1]-1]\n","#   Y_temp = Y_temp.replace('i','j')\n","#   Y_temp = complex(Y_temp)\n","#   # print(type(Y_temp))\n","#   # print(Y_temp,np.real(Y_temp),np.imag(Y_temp))\n","#   G_line1[i] = np.real(Y_temp)\n","#   B_line1[i] = np.imag(Y_temp)\n","\n","# G_line = G_line1\n","# B_line = B_line1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iqmiFrM_635P"},"outputs":[],"source":["print(type(G_line))\n","print(np.max(y_pred1[:,1,:]),np.min(y_pred1[:,1,:]))\n","print(np.max(theta),np.min(theta))\n","print(math.sin(math.pi/6))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dOwWVAYnTmCC"},"outputs":[],"source":["# B_line\n","import math\n","\n","# n_sample1 = 500\n","n_sample1 = n_sample\n","f_tot_sample1 = n_line*n_sample1\n","\n","# load true voltage file\n","filename1 = 'data_1354ac_2022/ieee1354_v.txt'\n","v_true = pd.read_table(filename1,sep=',',header=None).to_numpy()\n","print(v_true.shape)\n","\n","# load true theta file\n","filename2 = 'data_1354ac_2022/ieee1354_ieee1354_theta1.txt'\n","theta_true = pd.read_table(filename2,sep=',',header=None).to_numpy()\n","# theta_true = theta_true / 180 * math.pi\n","print(theta_true)\n","print(theta_true.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1mpVM770QeRp"},"outputs":[],"source":["# transformer indicator\n","# a = R_line > 0\n","a = np.ones(n_line)\n","\n","# Calculate real and reactive flow\n","f_p = np.zeros((n_line,n_sample1))\n","f_q = np.zeros((n_line,n_sample1))\n","fji_p = np.zeros((n_line,n_sample1))\n","fji_q = np.zeros((n_line,n_sample1))\n","print(f_q.shape)\n","\n","v_pred = y_pred1[:,1,:].copy()\n","v_pred = v_pred / 100 + 0.8\n","\n","# v_pred = v_true.copy()\n","# theta = theta_true.copy()\n","\n","print(np.max(v_pred),np.min(v_pred),v_pred.shape)\n","\n","for i in range(n_line):\n","  for j in range(n_sample1):\n","    f_p[i,j] = a[i] * v_pred[line_loc[i,0]-1,j] * v_pred[line_loc[i,0]-1,j] * G_line[i] \\\n","             - (a[i] * v_pred[line_loc[i,0]-1,j]) * v_pred[line_loc[i,1]-1,j] \\\n","             * (G_line[i] * math.cos(theta[line_loc[i,0]-1,j] - theta[line_loc[i,1]-1,j]) \\\n","              + B_line[i] * math.sin(theta[line_loc[i,0]-1,j] - theta[line_loc[i,1]-1,j]))\n","    f_q[i,j] =-(a[i] * v_pred[line_loc[i,0]-1,j]) **2 * (B_line[i] + B_shunt[i]/2) \\\n","             + a[i] * v_pred[line_loc[i,0]-1,j] * v_pred[line_loc[i,1]-1,j] \\\n","             * (B_line[i] * math.cos(theta[line_loc[i,0]-1,j] - theta[line_loc[i,1]-1,j]) \\\n","              - G_line[i] * math.sin(theta[line_loc[i,0]-1,j] - theta[line_loc[i,1]-1,j]))\n","             \n","    fji_p[i,j] = a[i] * v_pred[line_loc[i,1]-1,j] * v_pred[line_loc[i,1]-1,j] * G_line[i] \\\n","             - (a[i] * v_pred[line_loc[i,1]-1,j]) * v_pred[line_loc[i,0]-1,j] \\\n","             * (G_line[i] * math.cos(theta[line_loc[i,1]-1,j] - theta[line_loc[i,0]-1,j]) \\\n","              + B_line[i] * math.sin(theta[line_loc[i,1]-1,j] - theta[line_loc[i,0]-1,j]))\n","    fji_q[i,j] =-(a[i] * v_pred[line_loc[i,1]-1,j]) **2 * (B_line[i] + B_shunt[i]/2) \\\n","             + a[i] * v_pred[line_loc[i,1]-1,j] * v_pred[line_loc[i,0]-1,j] \\\n","             * (B_line[i] * math.cos(theta[line_loc[i,1]-1,j] - theta[line_loc[i,0]-1,j]) \\\n","              - G_line[i] * math.sin(theta[line_loc[i,1]-1,j] - theta[line_loc[i,0]-1,j]))         \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xKJjFdOtmEge"},"outputs":[],"source":["print('mean p_ij,q_ij:',np.mean(f_p),np.mean(f_q))\n","print('mean p_ji,q_ji:',np.mean(fji_p),np.mean(fji_q))\n","# print(f_q)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KfztNNMRkT2t"},"outputs":[],"source":["# theta = theta_true.copy()\n","print('Scale check:')\n","i=0;j=0\n","# a[0] = 1\n","a = np.ones(1751)\n","print('G,B,loc:',G_line[i],B_line[i],line_loc[i,0]-1,line_loc[i,1]-1) # G,B,line_loc verified\n","print('v:',v_pred[line_loc[i,0]-1,j],v_pred[line_loc[i,1]-1,j]) # v verified\n","print('theta:',theta[line_loc[i,0]-1,j],theta[line_loc[i,1]-1,j]) # theta verified\n","print('p,q:',f_p[0,0],f_q[0,0],fji_p[i,j],fji_q[i,j])\n","\n","\n","f_p_test = a[i] * v_pred[line_loc[i,0]-1,j] * v_pred[line_loc[i,0]-1,j] * G_line[i] \\\n","             - (a[i] * v_pred[line_loc[i,0]-1,j]) * v_pred[line_loc[i,1]-1,j] \\\n","             * (G_line[i] * math.cos(theta[line_loc[i,0]-1,j] - theta[line_loc[i,1]-1,j]) \\\n","              + B_line[i] * math.sin(theta[line_loc[i,0]-1,j] - theta[line_loc[i,1]-1,j]))\n","             \n","f_q_test =-(a[i] * v_pred[line_loc[i,0]-1,j]) **2 * (B_line[i] + B_shunt[i]/2) \\\n","             + a[i] * v_pred[line_loc[i,0]-1,j] * v_pred[line_loc[i,1]-1,j] \\\n","             * (B_line[i] * math.cos(theta[line_loc[i,0]-1,j] - theta[line_loc[i,1]-1,j]) \\\n","              - G_line[i] * math.sin(theta[line_loc[i,0]-1,j] - theta[line_loc[i,1]-1,j]))\n","             \n","print('test p/q:',f_p_test,f_q_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uZL1YUOypq4D"},"outputs":[],"source":["print(a[i],v_pred[line_loc[i,0]-1,j],B_line[i] + B_shunt[i]/2,v_pred[line_loc[i,1]-1,j])\n","print(G_line[i],math.cos(theta[line_loc[i,0]-1,j] - theta[line_loc[i,1]-1,j]),math.sin(theta[line_loc[i,0]-1,j] - theta[line_loc[i,1]-1,j]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mUya5mVOawWk"},"outputs":[],"source":["# Calculate apparent power\n","s_pred = np.zeros((n_line,n_sample1))\n","sji_pred = np.zeros((n_line,n_sample1))\n","\n","for i in range(n_line):\n","  for j in range(n_sample1):\n","    # s_pred[i,j] = np.sqrt(flow_est[i,j]**2 + f_q[i,j]**2)\n","    s_pred[i,j] = np.sqrt(f_p[i,j]**2 + f_q[i,j]**2)\n","    sji_pred[i,j] = np.sqrt(fji_p[i,j]**2 + fji_q[i,j]**2)\n","\n","s_pred = s_pred * 100 # p.u. to mva\n","sji_pred = sji_pred * 100 # p.u. to mva"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gKfcrbTSVMeO"},"outputs":[],"source":["# np.max(y_pred1[:,1,:]/100+0.8)\n","print(np.max(f_q),np.min(f_q))\n","flow_est.shape\n","\n","print(np.mean(s_pred[0,:]),np.mean(f_max_numpy[0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YO4__LJ2brLu"},"outputs":[],"source":["sij_binary = (np.abs(s_pred)-f_max_numpy[:n_line] > 0)\n","sji_binary = (np.abs(sji_pred)-f_max_numpy[:n_line] > 0)\n","s_binary = np.maximum(sij_binary,sji_binary)\n","\n","# sij_binary0 = (np.abs(flow_est0)-f_max_numpy > 0)\n","print(np.sum(s_binary))#,np.sum(f_binary0))\n","print('hard violation rate:',np.sum(s_binary)/f_tot_sample1)#,np.sum(f_binary0)/f_tot_sample)\n","\n","s_binary_soft = (np.abs(s_pred)-f_max_numpy[:n_line] > 0.1*(f_max_numpy[:n_line]))\n","# s_binary0_soft = (np.abs(flow_est0)-f_max_numpy > 0.1*(f_max_numpy))\n","print(np.sum(s_binary_soft))#,np.sum(f_binary0_soft))\n","print(np.sum(s_binary_soft)/f_tot_sample1)#,np.sum(f_binary0_soft)/f_tot_sample)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ty0WpBdfJwMR"},"outputs":[],"source":["# violation level\n","sij_violation = np.abs(s_pred)-f_max_numpy[:n_line] #/ f_max_numpy\n","sij_violation_level = np.maximum(sij_violation,0)\n","sji_violation = np.abs(sji_pred)-f_max_numpy[:n_line] #/ f_max_numpy\n","sji_violation_level = np.maximum(sji_violation,0)\n","\n","s_violation_level = np.maximum(sij_violation_level,sji_violation_level)\n","\n","s_violation_level = np.divide(s_violation_level,f_max_numpy[:n_line])\n","s_vio_lvl = np.reshape(s_violation_level,n_line*n_sample1)\n","\n","print('S violation level:')\n","print('hard:',np.sum(s_binary)/f_tot_sample1)\n","print('mean:',np.mean(s_vio_lvl))\n","print('median:',np.median(s_vio_lvl))\n","print('max:',np.max(s_vio_lvl))\n","print('std:',np.std(s_vio_lvl))\n","print('p99:',np.percentile(s_vio_lvl,99))\n","\n","f_violation = np.abs(flow_est)-f_max_numpy #/ f_max_numpy\n","f_violation_level = np.maximum(f_violation,0)\n","f_violation_level = np.divide(f_violation_level,f_max_numpy)\n","f_vio_lvl = np.reshape(f_violation_level,1991*n_sample)\n","\n","print('f violation level:')\n","print('hard:',np.sum(f_binary)/f_tot_sample,np.sum(f_binary0)/f_tot_sample)\n","print('mean:',np.mean(f_vio_lvl))\n","print('median:',np.median(f_vio_lvl))\n","print('max:',np.max(f_vio_lvl))\n","print('std:',np.std(f_vio_lvl))\n","print('p99:',np.percentile(f_vio_lvl,99))\n","\n","fig4 = plt.figure(figsize=(6,4))\n","plt.hist(s_vio_lvl, bins = 50, facecolor='b', alpha=0.75,label = 's violation')\n","plt.hist(f_vio_lvl, bins = 50, facecolor='r', alpha=0.75,label = 'f violation')\n","plt.legend(loc=\"upper right\")\n","plt.xlabel('violation level')\n","plt.ylabel('frequency')\n","# plt.title('injection histogram')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kWXEpj-ryjbJ"},"outputs":[],"source":["# err_L2_mean = np.mean(err_L2)\n","# err_Linf_mean = np.mean(err_Linf)\n","print('Price L2 mean:', err_L2_mean,'L_inf mean:', err_Linf_mean )\n","print('std:',np.std(err_L2))\n","# err_L2_mean_v = np.mean(err_L2_v)\n","# err_Linf_mean_v = np.mean(err_Linf_v)\n","print('Voltage L2 mean:', err_L2_mean_v,'L_inf mean:', err_Linf_mean_v )\n","print('std:',np.std(err_L2_v))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HwoGkJiG-rZh"},"outputs":[],"source":["# np.max(s_violation_level)\n","# s_violation_level[:,0]\n","# print(s_pred[:,0])\n","# print(f_max_numpy)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Puf_FCC4puLT"},"outputs":[],"source":["# # solve for Q\n","# from scipy.optimize import fsolve\n","\n","# # print(np.max(theta*180/2/math.pi),np.max(theta_true*180/2/math.pi))\n","\n","# def PF_eq(Q,V,G_mat,B_mat,n_bus,line_loc):\n","#   PF_obj = [None]*n_bus\n","#   for i in range(n_bus):\n","#     PF_obj[i] = \n","\n","#   return PF_obj\n","\n","# line_loc = np.nonzero(G_mat) # index of nonzero entries\n","# root = fsolve(PF_eq, np.zeros(118, args=(y_pred1[:,1,:0],G_mat,B_mat,n_bus,line_loc))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"daSZGfBY0XxN"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KHRJ468dBa76"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"1354ac_v_S_2side_feasgnn_03142022.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}