Package           Version
----------------- -----------
cycler            0.11.0
dataclasses       0.8
joblib            1.1.0
kiwisolver        1.3.1
matplotlib        3.3.4
numpy             1.19.5
pandas            1.1.5
Pillow            8.4.0
pip               21.3.1
pyparsing         3.0.7
python-dateutil   2.8.2
pytz              2021.3
scikit-learn      0.24.2
scipy             1.5.4
setuptools        39.0.1
six               1.16.0
sklearn           0.0
threadpoolctl     3.1.0
torch             1.7.1+cu110
torchaudio        0.7.2
torchvision       0.8.2+cu110
typing_extensions 4.1.0
118ac_dnn.py:128: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  right_thresh=torch.tensor(thresh).double()
Tesla V100-PCIE-16GB
(8000, 708)
(8000, 118)
number of params: 5796278
Epoch 0 | Train loss: 380.1485
Epoch 0 | Eval loss: 885.9940
Epoch 1 | Train loss: 377.2843
Epoch 2 | Train loss: 373.9702
Epoch 3 | Train loss: 369.8186
Epoch 4 | Train loss: 364.6656
Epoch 5 | Train loss: 358.3967
Epoch 5 | Eval loss: 517.9583
Epoch 6 | Train loss: 350.9460
Epoch 7 | Train loss: 342.3356
Epoch 8 | Train loss: 332.5677
Epoch 9 | Train loss: 321.7166
Epoch 10 | Train loss: 309.8690
Epoch 10 | Eval loss: 438.2962
Epoch 11 | Train loss: 297.1193
Epoch 12 | Train loss: 283.5501
Epoch 13 | Train loss: 269.3204
Epoch 14 | Train loss: 254.5279
Epoch 15 | Train loss: 239.3390
Epoch 15 | Eval loss: 347.0879
Epoch 16 | Train loss: 223.8871
Epoch 17 | Train loss: 208.3015
Epoch 18 | Train loss: 192.6977
Epoch 19 | Train loss: 177.2298
Epoch 20 | Train loss: 162.0308
Epoch 20 | Eval loss: 238.3118
Epoch 21 | Train loss: 147.2086
Epoch 22 | Train loss: 132.8775
Epoch 23 | Train loss: 119.1526
Epoch 24 | Train loss: 106.1105
Epoch 25 | Train loss: 93.8466
Epoch 25 | Eval loss: 554.6253
Epoch 26 | Train loss: 82.3964
Epoch 27 | Train loss: 71.8242
Epoch 28 | Train loss: 62.1543
Epoch 29 | Train loss: 53.3940
Epoch 30 | Train loss: 45.5217
Epoch 30 | Eval loss: 465.5785
Epoch 31 | Train loss: 38.5137
Epoch 32 | Train loss: 32.3526
Epoch 33 | Train loss: 26.9997
Epoch 34 | Train loss: 22.3776
Epoch 35 | Train loss: 18.4300
Epoch 35 | Eval loss: 378.1217
Epoch 36 | Train loss: 15.0983
Epoch 37 | Train loss: 12.3218
Epoch 38 | Train loss: 10.0177
Epoch 39 | Train loss: 8.1106
Epoch 40 | Train loss: 6.5766
Epoch 40 | Eval loss: 396.3633
Epoch 41 | Train loss: 5.3336
Epoch 42 | Train loss: 4.3285
Epoch 43 | Train loss: 3.5312
Epoch 44 | Train loss: 2.9052
Epoch 45 | Train loss: 2.3977
Epoch 45 | Eval loss: 1084.4909
Epoch 46 | Train loss: 2.0018
Epoch 47 | Train loss: 1.6784
Epoch 48 | Train loss: 1.4332
Epoch 49 | Train loss: 1.2276
Epoch 50 | Train loss: 1.0735
Epoch 50 | Eval loss: 376.4124
Epoch 51 | Train loss: 0.9422
Epoch 52 | Train loss: 0.8339
Epoch 53 | Train loss: 0.7493
Epoch 54 | Train loss: 0.6740
Epoch 55 | Train loss: 0.6130
Epoch 55 | Eval loss: 373.1698
Epoch 56 | Train loss: 0.5676
Epoch 57 | Train loss: 0.5246
Epoch 58 | Train loss: 0.4848
Epoch 59 | Train loss: 0.4432
Epoch 60 | Train loss: 0.4174
Epoch 60 | Eval loss: 393.0321
Epoch 61 | Train loss: 0.3849
Epoch 62 | Train loss: 0.3636
Epoch 63 | Train loss: 0.3445
Epoch 64 | Train loss: 0.3303
Epoch 65 | Train loss: 0.3128
Training time: 9.6590
13
L2 mean: 0.05128710777863212 L_inf mean: 0.10101933776360492
(8000, 708)
Dataset size: torch.Size([8000, 708])
Number of validation points::  8000
output size torch.Size([8000, 118])
reshaped size (8000, 118)
0.00016593933
0.81199646
0.005897377
0.2639952
(118, 8000)
<class 'numpy.ndarray'> 118 [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117]
(944000,)
-365164630000000.0 -2.9391174
(118, 8000)
(708, 1200) (708, 8000)
2217584.9820885705 2217584.9820885705
648078.7364409692 34540028.0 648078.7364409692
(118, 8000) (118, 8000)
mean p_inj l2 err: 0.2173092463150408
17669 11037
0.011874327956989247 0.007417338709677419
14369 8436
0.009656586021505376 0.005669354838709678
[[False  True False]
 [ True  True False]]
3
max sample pred: 19
max line pred: 4766
max sample true: 3
max line true: 8000
