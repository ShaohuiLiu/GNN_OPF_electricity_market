{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"118_gp.ipynb","provenance":[{"file_id":"1eNli6RpTRNC5pKHaMnv5iuCtz_A5odSO","timestamp":1610493842869}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"JKLovDeXoCCP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625946943425,"user_tz":300,"elapsed":24020,"user":{"displayName":"Hawk Liu","photoUrl":"","userId":"00179956829988677028"}},"outputId":"9474b2d0-6abe-4b12-a42b-a030b229c0c5"},"source":["import numpy as np\n","import pandas as pd\n","import time\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import time\n","from google.colab import drive\n","from sklearn.metrics import f1_score\n","drive.mount('/content/drive')\n","device='cuda' if torch.cuda.is_available() else 'cpu'\n","dataset=118\n","x=np.load('/content/drive/MyDrive/gnn/data/data_%d_linkpred/%d_linkpred_x.npy'%(dataset,dataset))\n","y=np.load('/content/drive/MyDrive/gnn/data/data_%d_linkpred/%d_linkpred_y.npy'%(dataset,dataset)).transpose()\n","y[y==2]=1\n","W=np.load('/content/drive/MyDrive/gnn/data/data_%d_linkpred/%d_linkpred_w.npy'%(dataset,dataset))\n","print(torch.cuda.get_device_name(0))"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","Tesla V100-SXM2-16GB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QF8DToBhDwqS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625946943426,"user_tz":300,"elapsed":7,"user":{"displayName":"Hawk Liu","photoUrl":"","userId":"00179956829988677028"}},"outputId":"661a5400-2a45-48c5-fb02-9f7d07b9d94e"},"source":["# sort activity\n","activity=np.sum(y,axis=0)\n","edges=np.argsort(activity)[::-1]\n","edge=edges[:10]\n","y=y[:,edge]\n","\n","gpw=(W!=0).astype(int)\n","from sklearn.model_selection import train_test_split\n","x_train,x_test,y_train,y_test = train_test_split(x.transpose(),y,test_size=0.2, random_state=18)\n","x_train=x_train.transpose()\n","x_test=x_test.transpose()\n","y_train=y_train.transpose()\n","y_test=y_test.transpose()\n","print('Training data size:',x_train.shape)\n","print('Training label size:',y_train.shape)\n","\n","class Dataset(torch.utils.data.Dataset):\n","    def __init__(self, features, labels, device='cpu'):\n","        self.features=torch.from_numpy(np.transpose(features)).float()\n","        self.labels=torch.from_numpy(np.transpose(labels)).float()\n","    def __len__(self):\n","        return len(self.features)\n","    def __getitem__(self, idx):\n","        if torch.is_tensor(idx): idx = idx.tolist()\n","        # Select sample\n","        X = self.features[idx]  # shape = (24,)\n","        y = self.labels[idx]    # shape = (24,)\n","        X = torch.reshape(X.t(),(1,-1))\n","        return X,y\n","params = {'batch_size':128,\n","          'shuffle': True,\n","          'num_workers':2}\n","# Dataset Generators\n","training_set=Dataset(features=x_train,labels=y_train,device=device)\n","training_generator=torch.utils.data.DataLoader(training_set,**params)\n","validation_set=Dataset(features=x_test,labels=y_test,device=device)\n","validation_generator=torch.utils.data.DataLoader(validation_set,**params)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Training data size: (118, 4, 8000)\n","Training label size: (10, 8000)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Jp3zMPW7NUb_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625946943827,"user_tz":300,"elapsed":405,"user":{"displayName":"Hawk Liu","photoUrl":"","userId":"00179956829988677028"}},"outputId":"b36c220e-071f-4c4c-8aa0-dc944b78aeaf"},"source":["W1=W.copy()\n","W1=np.asarray(W1)\n","W1=W1/1\n","W2=W1.copy()\n","print(type(W))\n","lam,v = np.linalg.eig(W1)\n","print(lam[0])\n","for i in range(5):\n","  W1 = np.matmul(W1,W2) / np.max(np.matmul(W1,W2))\n","  lam,v = np.linalg.eig(W1)\n","  print(lam[0])"],"execution_count":3,"outputs":[{"output_type":"stream","text":["<class 'numpy.ndarray'>\n","10.391198194095404\n","1.1997444434330222\n","1.2195765287586433\n","1.2295963414197528\n","1.2352295835641862\n","1.2386748374057457\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"J2fkZxWsoCGP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625946951529,"user_tz":300,"elapsed":7704,"user":{"displayName":"Hawk Liu","photoUrl":"","userId":"00179956829988677028"}},"outputId":"6250aea8-5f15-44a6-dda0-58621c5f5f35"},"source":["from torch.autograd import Variable\n","# One layer Graph convolution from nodes to edges\n","class graph_prune(nn.Module):\n","    def __init__(self,in_features,out_features,w,bias=True):\n","        super(graph_prune,self).__init__()\n","        # enlarge w\n","        W=np.zeros([w.shape[0]*in_features,w.shape[0]*out_features])\n","        for i in range(w.shape[0]):\n","          for j in range(w.shape[1]):\n","            W[i*in_features:(i+1)*in_features,j*out_features:(j+1)*out_features]+=1\n","        self.register_buffer('w',torch.from_numpy(W).float())\n","        self.mapping=nn.Parameter(torch.Tensor(W.shape[0],W.shape[1]))\n","        self.bias=nn.Parameter(torch.Tensor(1,W.shape[1]))\n","        torch.nn.init.xavier_uniform_(self.mapping.data)\n","        torch.nn.init.xavier_uniform_(self.bias.data)\n","\n","    def forward(self,input):\n","        h=torch.mul(self.mapping,self.w)\n","        h=torch.matmul(input,h)\n","        h=h+self.bias\n","        return h \n","\n","# graph prune NN\n","class GP(nn.Module):\n","    def __init__(self,in_feats,hidden_size,W,fc_params):\n","        super(GP, self).__init__()\n","        self.conv_v2v1=graph_prune(in_feats,hidden_size[0],W)\n","        self.conv_v2v2=graph_prune(hidden_size[0],hidden_size[1],W)\n","        self.conv_v2v3=graph_prune(hidden_size[1],hidden_size[2],W)\n","        self.conv_v2v4=graph_prune(hidden_size[2],hidden_size[3],W)\n","        self.conv_v2v5=graph_prune(hidden_size[3],hidden_size[4],W)\n","        self.conv_v2v6=graph_prune(hidden_size[4],hidden_size[5],W)\n","        self.linear1=nn.Linear(hidden_size[-1]*x_train.shape[0],fc_params[0])\n","        self.linear2=nn.Linear(fc_params[0],2*fc_params[1])\n","         \n","    def forward(self, inputs):\n","        # m = nn.ELU()\n","        # m = nn.LeakyReLU()\n","        # m = nn.Tanh()\n","        m = nn.ReLU()\n","        h=self.conv_v2v1(inputs)\n","        h=m(h)\n","        h=self.conv_v2v2(h)\n","        h=m(h)\n","        h=self.conv_v2v3(h)\n","        h=m(h)\n","        h=self.conv_v2v4(h)\n","        h=m(h)\n","        h=self.conv_v2v5(h)\n","        h=m(h)\n","        h=self.conv_v2v6(h)\n","        h=m(h)\n","        h=torch.squeeze(h)\n","        h=self.linear1(h)\n","        h=m(h)\n","        h=self.linear2(h)\n","        h=torch.reshape(h,(h.shape[0],2,-1))\n","        return h\n","hidden_size=[10,20,20,20,20,10]\n","net=GP(x_train.shape[1],hidden_size,gpw,[1000,len(edge)]) # Laplacian\n","net=net.to(device)\n","\n","optimizer=torch.optim.Adam(net.parameters())\n","loss_optm=[]\n","loss_val=[]\n","print(net)\n","print('number of params: %d'%(sum(temp.numel() for temp in net.parameters() if temp.requires_grad)))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["GP(\n","  (conv_v2v1): graph_prune()\n","  (conv_v2v2): graph_prune()\n","  (conv_v2v3): graph_prune()\n","  (conv_v2v4): graph_prune()\n","  (conv_v2v5): graph_prune()\n","  (conv_v2v6): graph_prune()\n","  (linear1): Linear(in_features=1180, out_features=1000, bias=True)\n","  (linear2): Linear(in_features=1000, out_features=20, bias=True)\n",")\n","number of params: 24048180\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iu0PKvcgF2vN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625946985190,"user_tz":300,"elapsed":33673,"user":{"displayName":"Hawk Liu","photoUrl":"","userId":"00179956829988677028"}},"outputId":"aa7e0bb3-75fe-4d2a-f4c8-551c2cd57d3a"},"source":["t0=time.time()\n","max_epochs=200\n","eval_epoch=5\n","\n","# earlystopping\n","tolerance=10\n","min_delta=1e-3\n","previous=0\n","\n","W_tensor=torch.from_numpy(W).float().to(device)\n","my_loss_func=nn.CrossEntropyLoss()\n","for epoch in range(max_epochs):\n","  # training loop\n","  train_loss=0.0\n","  for local_batch,local_label in training_generator:\n","    optimizer.zero_grad() # clear the past gradient\n","    local_batch,local_label=local_batch.to(device),local_label.to(device)\n","    logits=net(local_batch)\n","    loss=my_loss_func(logits,local_label.long())\n","    loss.backward()\n","    train_loss+=loss.item()\n","    optimizer.step() # update parameters of net\n","  loss_optm.append(train_loss/len(training_generator.dataset))\n","  print(\"Epoch %d | Training loss: %.8f\"%(epoch,train_loss/len(training_generator.dataset)))\n","  # eval\n","  if (epoch+1)%eval_epoch==0:\n","    net.eval()\n","    eval_loss=0.0\n","    for eval_batch,eval_label in validation_generator:\n","      eval_batch,eval_label=eval_batch.to(device),eval_label.to(device)\n","      logits=net(eval_batch)\n","      loss=loss=my_loss_func(logits,eval_label.long())\n","      eval_loss+=loss.item()\n","    eval_avg=eval_loss/len(validation_generator.dataset)\n","    if (epoch==0): previous=eval_avg\n","    else:\n","      if previous-eval_avg<min_delta: tolerance-=1\n","      if tolerance==0: break\n","      previous=eval_avg\n","    print(\"Epoch %d | Eval loss: %.8f\" % (epoch, eval_avg))\n","    loss_val.append([epoch, eval_loss/len(validation_generator.dataset)])\n","    net.train()\n","t1=time.time()\n","print(\"Training time:%.4fs\"%(t1-t0))\n","path='/content/drive/MyDrive/gnn/linkpred/%d_gp.pickle'%(dataset)\n","torch.save(net.state_dict(),path)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Epoch 0 | Training loss: 0.00796363\n","Epoch 1 | Training loss: 0.00055859\n","Epoch 2 | Training loss: 0.00054976\n","Epoch 3 | Training loss: 0.00054015\n","Epoch 4 | Training loss: 0.00053983\n","Epoch 4 | Eval loss: 0.00051349\n","Epoch 5 | Training loss: 0.00050672\n","Epoch 6 | Training loss: 0.00051367\n","Epoch 7 | Training loss: 0.00051070\n","Epoch 8 | Training loss: 0.00049619\n","Epoch 9 | Training loss: 0.00051307\n","Epoch 9 | Eval loss: 0.00047553\n","Epoch 10 | Training loss: 0.00049341\n","Epoch 11 | Training loss: 0.00051003\n","Epoch 12 | Training loss: 0.00049269\n","Epoch 13 | Training loss: 0.00050377\n","Epoch 14 | Training loss: 0.00049002\n","Epoch 14 | Eval loss: 0.00048882\n","Epoch 15 | Training loss: 0.00050473\n","Epoch 16 | Training loss: 0.00048915\n","Epoch 17 | Training loss: 0.00049634\n","Epoch 18 | Training loss: 0.00048611\n","Epoch 19 | Training loss: 0.00047892\n","Epoch 19 | Eval loss: 0.00050540\n","Epoch 20 | Training loss: 0.00048697\n","Epoch 21 | Training loss: 0.00048413\n","Epoch 22 | Training loss: 0.00048322\n","Epoch 23 | Training loss: 0.00047922\n","Epoch 24 | Training loss: 0.00047917\n","Epoch 24 | Eval loss: 0.00049612\n","Epoch 25 | Training loss: 0.00047254\n","Epoch 26 | Training loss: 0.00049604\n","Epoch 27 | Training loss: 0.00048156\n","Epoch 28 | Training loss: 0.00049046\n","Epoch 29 | Training loss: 0.00046666\n","Epoch 29 | Eval loss: 0.00045309\n","Epoch 30 | Training loss: 0.00046917\n","Epoch 31 | Training loss: 0.00046143\n","Epoch 32 | Training loss: 0.00048313\n","Epoch 33 | Training loss: 0.00045603\n","Epoch 34 | Training loss: 0.00047507\n","Epoch 34 | Eval loss: 0.00054762\n","Epoch 35 | Training loss: 0.00046030\n","Epoch 36 | Training loss: 0.00045636\n","Epoch 37 | Training loss: 0.00045576\n","Epoch 38 | Training loss: 0.00046888\n","Epoch 39 | Training loss: 0.00045523\n","Epoch 39 | Eval loss: 0.00045773\n","Epoch 40 | Training loss: 0.00044948\n","Epoch 41 | Training loss: 0.00045268\n","Epoch 42 | Training loss: 0.00045040\n","Epoch 43 | Training loss: 0.00046491\n","Epoch 44 | Training loss: 0.00045010\n","Epoch 44 | Eval loss: 0.00044883\n","Epoch 45 | Training loss: 0.00045399\n","Epoch 46 | Training loss: 0.00044336\n","Epoch 47 | Training loss: 0.00044994\n","Epoch 48 | Training loss: 0.00045968\n","Epoch 49 | Training loss: 0.00045278\n","Training time:30.3025s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hAK7aPR14i6a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625946985365,"user_tz":300,"elapsed":187,"user":{"displayName":"Hawk Liu","photoUrl":"","userId":"00179956829988677028"}},"outputId":"110eebeb-36df-4490-c9ad-fe49fe2c9173"},"source":["net.load_state_dict(torch.load(path))\n","# validate on test set\n","net.eval()\n","x_test_feed=torch.from_numpy(x_test.transpose()).float()\n","x_test_feed=torch.reshape(x_test_feed,(x_test_feed.shape[0],1,-1))\n","x_test_feed=x_test_feed.to(device)\n","y_pred=net(x_test_feed)\n","y_pred=torch.argmax(y_pred,dim=1)\n","y_pred1=y_pred.cpu().detach()\n","y_pred1=y_pred1.numpy().transpose()\n","print('Validation dataset size:',x_test_feed.shape)\n","print(y_pred.shape)\n","print(y_test.shape)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Validation dataset size: torch.Size([2000, 1, 472])\n","torch.Size([2000, 10])\n","(10, 2000)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cizlIh794l7A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625946985550,"user_tz":300,"elapsed":186,"user":{"displayName":"Hawk Liu","photoUrl":"","userId":"00179956829988677028"}},"outputId":"f5c1b343-0c8d-4e2c-886a-53cdaf38938e"},"source":["y_diff = np.abs(y_test - y_pred1)\n","print(np.sum(y_diff)/np.sum(y_test))\n","# print(y_pred1,y_test)\n","print(np.sum(y_pred1),np.sum(y_test))\n","print('--')\n","print('positive accuracy:',np.sum(y_pred1==y_test)/y_test.shape[0]/y_test.shape[1])\n","print('--')\n","for edge in range(10):\n","  print(f1_score(y_pred1[edge,:],y_test[edge,:]))\n","print('--')\n","print(f1_score(y_pred1.reshape(-1,),y_test.reshape(-1,)))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["0.07456445993031359\n","4000 4305.0\n","--\n","positive accuracy: 0.98395\n","--\n","1.0\n","0.9979959919839679\n","0.0\n","0.0\n","0.0\n","0.0\n","0.0\n","0.0\n","0.0\n","0.0\n","--\n","0.9613485851896448\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n","  average, \"true nor predicted\", 'F-score is', len(true_sum)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"BBjsQrwYdRPT","executionInfo":{"status":"ok","timestamp":1625946985550,"user_tz":300,"elapsed":3,"user":{"displayName":"Hawk Liu","photoUrl":"","userId":"00179956829988677028"}}},"source":[""],"execution_count":7,"outputs":[]}]}