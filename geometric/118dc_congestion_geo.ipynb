{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"118dc_congestion_geo.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"fprlsHizP6HO"},"source":["# install pytorch geometric\n","!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.9.0+cu111.html --quiet"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JKLovDeXoCCP","executionInfo":{"status":"ok","timestamp":1633914548107,"user_tz":300,"elapsed":6,"user":{"displayName":"Chengyang Wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13034480122279130235"}},"outputId":"cb377414-7e64-4d88-956e-f1d2d9a388d4"},"source":["import numpy as np\n","import pandas as pd\n","import time\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import time\n","from google.colab import drive\n","drive.mount('/content/drive')\n","device='cuda' if torch.cuda.is_available() else 'cpu'\n","print(torch.cuda.get_device_name(0))\n","\n","from torch_geometric.data import Data\n","from torch_geometric.loader import DataLoader\n","from torch_geometric.nn import GCNConv"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Tesla K80\n"]}]},{"cell_type":"code","metadata":{"id":"d6DPduspQKy-"},"source":["# pseudo graph\n","# with open('/content/drive/MyDrive/gnn/geometric/118_edge_index.txt','w') as f:\n","#   for source in range(118):\n","#     for target in range(118):\n","#       if source!=target:\n","#         f.write('%d\\t%d\\n'%(source,target))\n","#         f.write('%d\\t%d\\n'%(target,source))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w6jhARwKRMiw"},"source":["# read edge index\n","total=open('/content/drive/MyDrive/gnn/geometric/118_edge_index.txt','r').readlines()\n","edges=[[],[]]\n","for line in total:\n","  [source,target]=line.strip().split()\n","  edges[0].append(int(source))\n","  edges[1].append(int(target))\n","edge_index=torch.tensor(edges,dtype=torch.long)\n","x=np.load('/content/drive/MyDrive/gnn/data/dc118_p10_x_congest1.npy').transpose(2,0,1)\n","y=np.load('/content/drive/MyDrive/gnn/data/dc118_p10_y_congest1.npy').transpose()\n","y=np.expand_dims(y,axis=2)\n","W=np.load('/content/drive/MyDrive/gnn/data/dc118_p10_w.npy')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"odmJhGFMShbd"},"source":["# x and y are combined in PyG data\n","data=[]\n","for idx in range(y.shape[0]):\n","  graph=Data(x=torch.tensor(x[idx],dtype=torch.float),y=torch.tensor(y[idx],dtype=torch.float))\n","  data.append(graph)\n","train=data[:int(len(data)*0.8)]\n","test=data[int(len(data)*0.8):]\n","train_loader=DataLoader(train,batch_size=32,shuffle=True)\n","test_loader=DataLoader(test,batch_size=32,shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rapvnWEckmQL"},"source":["class GCN(torch.nn.Module):\n","  def __init__(self,edge_index,hidden,num_bus):\n","    super().__init__()\n","    self.edge_index=edge_index\n","    self.conv=[GCNConv(-1,hidden[0])]\n","    for idx in range(len(hidden)-1):\n","      self.conv.append(GCNConv(hidden[idx],hidden[idx+1]))\n","    self.linear=nn.Linear(hidden[-1],num_bus)\n","  \n","  def forward(self,input):\n","    x=input.x\n","    for layer in self.conv:\n","      x=layer.forward(x,self.edge_index)\n","    return x\n","num_bus=y.shape[-1]\n","hidden=[5,10,1]\n","net=GCN(edge_index,hidden,num_bus)\n","net=net\n","\n","loss_func=nn.MSELoss()\n","optimizer=torch.optim.Adam(net.parameters(),weight_decay=0.01)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":578},"id":"iu0PKvcgF2vN","executionInfo":{"status":"error","timestamp":1633914577853,"user_tz":300,"elapsed":29112,"user":{"displayName":"Chengyang Wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13034480122279130235"}},"outputId":"c47f8a04-af86-4982-a741-f5ec0b0dce4c"},"source":["max_epochs=100\n","eval_epoch=10\n","\n","# earlystopping\n","tolerance= 4\n","min_delta=5e-4\n","previous=0\n","\n","loss_train=[]\n","loss_eval=[]\n","for epoch in range(max_epochs):\n","  # training loop\n","  train_loss=0.0\n","  for batch in train_loader:\n","    batch=batch\n","    optimizer.zero_grad()\n","    logits=net(batch)\n","    loss=loss_func(logits,batch.y)\n","    loss.backward()\n","    train_loss+=loss.item()\n","    optimizer.step() # update parameters of net\n","  train_avg=train_loss/len(train_loader.dataset)\n","  loss_train.append(train_avg)\n","  print(\"Epoch %d | Training loss: %.4f\"%(epoch,train_avg))\n","  # eval\n","  if (epoch+1)%eval_epoch==0:\n","    net.eval()\n","    eval_loss=0.0\n","    for batch in test_loader:\n","      batch=batch\n","      logits=net(batch)\n","      loss=loss_func(logits,batch.y)\n","      eval_loss+=loss.item()\n","    eval_avg=eval_loss/len(test_loader.dataset)\n","    if (epoch==0): previous=eval_avg\n","    else:\n","      if previous-eval_avg<min_delta: tolerance-=1\n","      if tolerance==0: break\n","      previous=eval_avg\n","    print(\"Epoch %d | Eval loss: %.4f\" % (epoch,eval_avg))\n","    loss_eval.append([epoch,eval_avg])\n","    net.train()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0 | Training loss: 24.8821\n","Epoch 1 | Training loss: 24.8828\n","Epoch 2 | Training loss: 24.8822\n","Epoch 3 | Training loss: 24.8865\n","Epoch 4 | Training loss: 24.8796\n","Epoch 5 | Training loss: 24.8807\n","Epoch 6 | Training loss: 24.8836\n","Epoch 7 | Training loss: 24.8849\n","Epoch 8 | Training loss: 24.8822\n","Epoch 9 | Training loss: 24.8867\n","Epoch 9 | Eval loss: 26.3503\n","Epoch 10 | Training loss: 24.8839\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-203-9cc70108e64f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# update parameters of net\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"L3M4jmjkscK_"},"source":["\n","import matplotlib.pyplot as plt\n","\n","val_len = len(loss_eval)\n","print(val_len)\n","val_plt = np.zeros((2,val_len))\n","for i in range(val_len):\n","  val_plt[0,i] = loss_eval[i][0]\n","  val_plt[1,i] = loss_eval[i][1]\n","\n","plt.figure()\n","plot_idx = np.arange(np.size(loss_optm))\n","# plt.plot(plot_idx,loss_optm,lw=2,label='training loss')\n","# plt.plot(val_plt[0,:],val_plt[1,:],lw=2,label='validation loss')\n","plt.plot(plot_idx[5:-1],loss_optm[5:-1],lw=2,label='training loss')\n","plt.plot(val_plt[0,1:],val_plt[1,1:],lw=2,label='validation loss')\n","plt.yscale(\"log\")\n","plt.xlabel('epoch')\n","plt.ylabel('loss')\n","plt.legend()\n","plt.show(block=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4u6001UQ2pN3"},"source":["n_test = 2000\n","x_test_feed = torch.from_numpy(np.transpose(x_test)).float()\n","x_test_feed = x_test_feed.to(device)\n","y_pred = net(x_test_feed)\n","print('Validation dataset size:',x_test_feed.shape)\n","print('Number of validation set: ',n_test)\n","y_pred1=y_pred.cpu().detach()\n","y_pred1=torch.squeeze(y_pred1,1).numpy().transpose()\n","print(y_test.shape)\n","\n","n_test = np.size(y_test,1)\n","err_L2 = np.zeros(n_test)\n","err_Linf = np.zeros(n_test)\n","for i in range(n_test):\n","  err_L2[i] = np.linalg.norm(y_test[:,i] - y_pred1[:,i]) / np.linalg.norm(y_test[:,i])\n","  err_Linf[i] = np.max(np.abs(y_test[:,i] - y_pred1[:,i])) / np.max(np.abs(y_test[:,i]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"79xFCVXklkLb"},"source":["err_L2_mean = np.mean(err_L2)\n","err_Linf_mean = np.mean(err_Linf)\n","print('L2 mean:', err_L2_mean,'L_inf mean:', err_Linf_mean )\n","\n","fig2 = plt.figure(figsize=(16, 8))\n","plt.subplot(1, 2, 1)\n","# plt.hist(np.abs(ga),bins = 10)\n","plt.plot(err_L2,'bo',markersize=0.5,label = 'L2 error')\n","plt.plot(err_Linf,'r^',markersize=0.5,label = 'Linf error')\n","plt.legend(loc=\"upper right\")\n","plt.xlabel('sample index')\n","plt.ylabel('error')\n","plt.title('Normalized sample error')\n","plt.grid(True)\n","# error histogram\n","plt.subplot(1, 2, 2)\n","plt.hist(err_L2, bins = 50, facecolor='b', alpha=0.75,label = 'L2 error')\n","plt.hist(err_Linf, bins = 50, facecolor='g', alpha=0.75,label = 'Linf error')\n","plt.legend(loc=\"upper right\")\n","plt.xlabel('sample error value')\n","plt.ylabel('frequency')\n","plt.title('Histogram of L_2 error')\n","# plt.text(60, .025, r'$\\mu=100,\\ \\sigma=15$')\n","plt.grid(True)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gWknseXjRr3r"},"source":["index = 1\n","y_test_copy = y_pred1[:,index].copy()\n","print(y_test_copy.shape)\n","for i in range(118):\n","  if y_test_copy[i] < 0.1:\n","    y_test_copy[i] = y_test[i,index] + 50\n","print(np.linalg.norm(y_test_copy - y_test[:,index]) / np.linalg.norm(y_test[:,index]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H9x7neMNj7n3"},"source":["# Predict generation using $\\pi$\n","* Using predicted $\\pi$ and find the active constraints in $p_G(i)$\n","* For inactive $p_G(i)$ consider other methods like power flow balance"]},{"cell_type":"code","metadata":{"id":"Kr29K04j2KTN"},"source":["gen_limit0 = x[:,2,:].copy()\n","print(gen_limit0.shape)\n","\n","gen_idx = []\n","for i in range(n_bus):\n","  if gen_limit0[i,0] > 0:\n","    gen_idx.append(i)\n","print(type(gen_idx),len(gen_idx),gen_idx)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7LUcg6DDk13A"},"source":["# # get the generator index\n","# # generator cost data\n","# gen_cost0\n","# # generator limit data\n","# gen_limit0\n","# # LMP data\n","# lmp_data\n","# # generation data\n","# gen_data\n","\n","load_data = x.copy()\n","print(load_data.shape)\n","n_sample = np.size(load_data,2)\n","\n","x_val_feed = torch.from_numpy(np.transpose(load_data)).float()\n","x_val_feed = x_val_feed.to(device)\n","\n","print('Dataset size:',x_val_feed.shape)\n","print('Number of validation points:: ',n_sample)\n","y_pred = net(x_val_feed) # predict the corredponding LMP\n","\n","y_pred1 = y_pred.cpu().detach()\n","y_pred1 = torch.squeeze(y_pred1,1).numpy().transpose()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DIMUWHsL5tdd"},"source":["* Save results"]},{"cell_type":"code","metadata":{"id":"EeDi2jga6eON"},"source":["# dataset = {'lmp_pred': y_pred1, 'lmp_true': lmp_data}\n","# print('Pred:',y_pred1.shape,'True:',lmp_data.shape)\n","\n","# file_name = 'dc118_lmp_prediction_p10'\n","# file_path = 'drive/My Drive/gnn/data/results/'\n","# file_dir = file_path + file_name + '.pickle'\n","# outfile = open(file_dir, 'wb')\n","# pickle.dump(dataset, outfile)\n","# outfile.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EHWY5moJ6gin"},"source":["import pickle\n","gen_cost0 = x[:,1,:].copy()\n","lmp_data = y.copy()\n","\n","profit_pred = y_pred1 - gen_cost0\n","print(np.min(np.abs(profit_pred)))\n","\n","profit_true = lmp_data - gen_cost0\n","\n","gen_pred_binary = np.zeros((len(gen_idx),n_sample))\n","gen_true_binary = np.zeros((len(gen_idx),n_sample))\n","print(gen_pred_binary.shape)\n","\n","binary_thres = 0.97\n","binary_thres_true = 1e-5\n","\n","for i in range(n_sample):\n","  for j in range(len(gen_idx)):\n","    # predicted generator limit\n","    if profit_pred[gen_idx[j],i] > binary_thres:\n","      gen_pred_binary[j,i] = 1\n","    elif profit_pred[gen_idx[j],i] < 1-binary_thres:\n","      gen_pred_binary[j,i] = 0\n","    else:\n","      gen_pred_binary[j,i] = 0.5\n","    # true generator limit\n","    if profit_true[gen_idx[j],i] > binary_thres_true:\n","      gen_true_binary[j,i] = 1\n","    elif profit_true[gen_idx[j],i] < 1e-5:\n","      gen_true_binary[j,i] = 0\n","    else:\n","      gen_true_binary[j,i] = 0.5\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bISzkOX52XJM"},"source":["gen_binary_err = np.abs(gen_true_binary - gen_pred_binary)\n","print('max binary error:',np.max(gen_binary_err))\n","# count the wrong entries\n","gen_binary_err_ct = np.sum(gen_binary_err)\n","gen_binary_err_ratio = gen_binary_err_ct / (len(gen_idx)*n_sample)\n","print('Binary accuracy:',1-gen_binary_err_ratio)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nnNXdj-v6-7I"},"source":["print(gen_limit0.shape)\n","print(np.transpose(x_test).shape,np.transpose(load_data).shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qC6Ju7atWC5d"},"source":[""],"execution_count":null,"outputs":[]}]}